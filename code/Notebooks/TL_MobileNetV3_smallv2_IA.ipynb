{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "577a39f9",
   "metadata": {},
   "source": [
    "# Transfer Learning using MobileNetV3_Small - Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7f5404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c533c7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir =pathlib.Path('/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/data/Training and Validation')\n",
    "test_dir =pathlib.Path('/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/data/Testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f486566",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d003e205",
   "metadata": {},
   "outputs": [],
   "source": [
    "fire = list(data_dir.glob('fire/*'))\n",
    "img = PIL.Image.open(str(fire[0]))\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337fab46",
   "metadata": {},
   "source": [
    "### Using Image Generator to load data into tf dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a9ef1c",
   "metadata": {},
   "source": [
    "Image input sizes: https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8956881",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    "# Validation split 80/20\n",
    "# Training generator\n",
    "\n",
    "training_gen = ImageDataGenerator(horizontal_flip=True,\n",
    "                                  vertical_flip=True,\n",
    "                                  zoom_range=0.2,\n",
    "                                  width_shift_range=0.2,\n",
    "                                  height_shift_range=0.2,\n",
    "                                  brightness_range = (0.75, 1.25),\n",
    "                                  validation_split=0.2,\n",
    "                                  rotation_range = 30)\n",
    "\n",
    "# Training dataset\n",
    "train_ds = training_gen.flow_from_directory(data_dir, \n",
    "                                            target_size=(img_height, img_width), \n",
    "                                            color_mode = 'rgb',\n",
    "                                            class_mode='binary',\n",
    "                                            batch_size=batch_size,\n",
    "                                            subset='training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf95709",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ds = training_gen.flow_from_directory(data_dir,\n",
    "                                            target_size=(img_height, img_width),\n",
    "                                            color_mode='rgb',\n",
    "                                            class_mode = 'binary',\n",
    "                                            batch_size=batch_size,\n",
    "                                            subset='validation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eeac62",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    shuffle = True,\n",
    "    seed = 123,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a036fce",
   "metadata": {},
   "source": [
    "## Seeing what augmentation is applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00292533",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import expand_dims\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99eaa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img(f'{data_dir}/fire/fire_0132.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ac08fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "data = img_to_array(img)\n",
    "samples = expand_dims(data, 0)\n",
    "it = training_gen.flow(samples, batch_size=1)\n",
    "\n",
    "\n",
    "# generate samples and plot\n",
    "for i in range(3):\n",
    "\t# define subplot\n",
    "\tpyplot.figure(figsize=(25,25))\n",
    "pyplot.subplot(330 + 1+i)\n",
    "\t# generate batch of images\n",
    "batch = it.next()\n",
    "\t# convert to unsigned integers for viewing\n",
    "image = batch[0].astype('uint8')\n",
    "\t# plot raw pixel data\n",
    "pyplot.imshow(image)\n",
    "# show the figure\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203a9337",
   "metadata": {},
   "source": [
    "### Get Class Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eb59b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = list(train_ds.class_indices.keys())\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89d6dac",
   "metadata": {},
   "source": [
    "### Configure the dataset for performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73585ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# train_ds = train_ds.prefetch(buffer_size = AUTOTUNE)\n",
    "# valid_ds = valid_ds.prefetch(buffer_size = AUTOTUNE)\n",
    "# test_ds = test_ds.prefetch(buffer_size = AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eacd4ec",
   "metadata": {},
   "source": [
    "### Create the base model from pre-trained convnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3848b9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## By specifying \"include_top=False\" argument you load a network that doesn't \n",
    "## include the classification layers at the top, which is ideal for feature extraction\n",
    "\n",
    "IMG_SHAPE = (img_width, img_height) + (3,)\n",
    "\n",
    "base_model = tf.keras.applications.MobileNetV3Small(\n",
    "    input_shape=IMG_SHAPE,\n",
    "    alpha=1.0,\n",
    "    minimalistic=False,\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_tensor=None,\n",
    "    pooling=None,\n",
    "    dropout_rate=0.2,\n",
    "    classifier_activation='softmax',\n",
    "    include_preprocessing=True\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "image_batch, label_batch = next(iter(train_ds))\n",
    "feature_batch = base_model(image_batch)\n",
    "print(feature_batch.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d556cb85",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9565031",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a588b0",
   "metadata": {},
   "source": [
    "## Add classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646d6dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "feature_batch_average = global_average_layer(feature_batch)\n",
    "print(feature_batch_average.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731a52e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_layer = tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "prediction_batch = prediction_layer(feature_batch_average)\n",
    "print(prediction_batch.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c14432",
   "metadata": {},
   "source": [
    "### Chain together the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434043f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape = (IMG_SHAPE))\n",
    "x = base_model(inputs, training = False)\n",
    "x = global_average_layer(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38854ac",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf891c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful metrics paper:\n",
    "# https://www.tensorflow.org/tutorials/structured_data/imbalanced_data\n",
    "\n",
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = base_learning_rate),\n",
    "              loss = tf.keras.losses.BinaryCrossentropy(from_logits=(True)),\n",
    "              metrics = [tf.keras.metrics.Precision(name = \"precision\"), \n",
    "                         tf.keras.metrics.Recall(name = \"recall\"),\n",
    "                         tf.keras.metrics.AUC(name = \"auc\")] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ecfa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e69fcf2",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cb8078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests the initial base model\n",
    "initial_epochs = 10\n",
    "loss0, precision0, recall0, auc0 = model.evaluate(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23442254",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"initial loss: {:.2f}\".format(loss0))\n",
    "print(\"initial precision: {:.2f}\".format(precision0))\n",
    "print(\"initial recall: {:.2f}\".format(recall0))\n",
    "print(\"initial auc: {:.2f}\".format(auc0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddd5b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds,\n",
    "                    epochs = initial_epochs,\n",
    "                    validation_data = valid_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cf5555",
   "metadata": {},
   "source": [
    "### Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99220703",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = history.history['recall']\n",
    "val_recall = history.history['val_recall']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "auc = history.history['auc']\n",
    "val_auc = history.history['val_auc']\n",
    "\n",
    "precision = history.history['precision']\n",
    "val_pre = history.history['val_precision']\n",
    "\n",
    "plt.figure(figsize = (16, 16))\n",
    "plt.subplot(4, 2, 1)\n",
    "plt.plot(recall, label = 'Training Recall')\n",
    "plt.plot(val_recall, label='Validation Recall')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    shuffle = True,\n",
    "    seed = 123,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    "    )\n",
    "\n",
    "plt.subplot(4, 2, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(4, 2, 3)\n",
    "plt.plot(auc, label = 'Training AUC')\n",
    "plt.plot(val_auc, label='Validation AUC')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('AUC')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation AUC')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(4, 2, 4)\n",
    "plt.plot(precision, label = 'Training Precision')\n",
    "plt.plot(val_pre, label='Validation Precision')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Precision')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f6d61b",
   "metadata": {},
   "source": [
    "## Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc675c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previously the base model weights were not updated and only a few layers on top of the EfficientNetV2 was trained\n",
    "# Unfreeze and train the top layers of the pre-trained model to fine tune to the dataset\n",
    "\n",
    "## Un-freeze top layers of the model\n",
    "\n",
    "base_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e039116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look to see how many layers are in the base model\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30f4bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 100\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b78e384",
   "metadata": {},
   "source": [
    "### Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b60eb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Important to use a lower training weight since using more layers, otherwise\n",
    "# it could overfit very quickly \n",
    "\n",
    "model.compile(loss = tf.keras.losses.BinaryCrossentropy(from_logits = True),\n",
    "              optimizer = tf.keras.optimizers.RMSprop(learning_rate = base_learning_rate/10),\n",
    "              metrics = [tf.keras.metrics.Precision(name = \"precision\"), tf.keras.metrics.Recall(name = \"recall\"),tf.keras.metrics.AUC(name = \"auc\")])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d543d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(model.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238b6d3b",
   "metadata": {},
   "source": [
    "### Continue Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40db2745",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_epochs = 10\n",
    "total_epochs = initial_epochs + fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(train_ds,\n",
    "                         epochs = total_epochs,\n",
    "                         initial_epoch = history.epoch[-1],\n",
    "                         validation_data = valid_ds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e306396",
   "metadata": {},
   "source": [
    "### Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf88e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall += history_fine.history['recall']\n",
    "val_recall += history_fine.history['val_recall']\n",
    "\n",
    "loss += history_fine.history['loss']\n",
    "val_loss += history_fine.history['val_loss']\n",
    "\n",
    "auc += history_fine.history['auc']\n",
    "val_auc += history_fine.history['val_auc']\n",
    "\n",
    "precision += history_fine.history['precision']\n",
    "val_pre += history_fine.history['val_precision']\n",
    "\n",
    "plt.figure(figsize = (16, 16))\n",
    "plt.subplot(4, 2, 1)\n",
    "plt.plot(recall, label = 'Training Recall')\n",
    "plt.plot(val_recall, label='Validation Recall')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.title('Training and Validation Recall')\n",
    "\n",
    "plt.subplot(4, 2, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(4, 2, 3)\n",
    "plt.plot(auc, label = 'Training AUC')\n",
    "plt.plot(val_auc, label='Validation AUC')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('AUC')\n",
    "plt.ylim([0.7,1.0])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.title('Training and Validation AUC')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(4, 2, 4)\n",
    "plt.plot(precision, label = 'Training Precision')\n",
    "plt.plot(val_pre, label='Validation Precision')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.7,1.0])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.title('Training and Validation Precision')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e96f150",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    shuffle = True,\n",
    "    seed = 123,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060cebc0",
   "metadata": {},
   "source": [
    "## Verifying on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396da123",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, precision, recall, auc = model.evaluate(test_ds)\n",
    "print('Test loss :', loss)\n",
    "print('Test precision :', precision)\n",
    "print('Test recall :', recall)\n",
    "print('Test auc :', auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74a4318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve a batch of images from the test set\n",
    "image_batch, label_batch = test_ds.as_numpy_iterator().next()\n",
    "predictions = model.predict_on_batch(image_batch).flatten()\n",
    "\n",
    "# pred = model.predict(test_ds)\n",
    "# pred = np.argmax(pred, axis = 1)[:5]\n",
    "# label = \n",
    "\n",
    "# Apply a sigmoid since our model returns logits\n",
    "#predictions = tf.nn.sigmoid(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955702b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.round(predictions, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41597eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fc5570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve a batch of images from the test set\n",
    "image_batch, label_batch = test_ds.as_numpy_iterator().next()\n",
    "predictions = model.predict_on_batch(image_batch).flatten()\n",
    "\n",
    "# pred = model.predict(test_ds)\n",
    "# pred = np.argmax(pred, axis = 1)[:5]\n",
    "# label = \n",
    "\n",
    "# Apply a sigmoid since our model returns logits\n",
    "#predictions = tf.nn.sigmoid(predictions)\n",
    "predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "\n",
    "print('Predictions:\\n', predictions.numpy())\n",
    "print('Labels:\\n', label_batch)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "  ax = plt.subplot(3, 3, i + 1)\n",
    "  plt.imshow(image_batch[i].astype(\"uint8\"))\n",
    "  plt.title(class_names[predictions[i]])\n",
    "  plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffc499e",
   "metadata": {},
   "source": [
    "## Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9615b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('IA_model00_MobileNetv3_Small.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469bd300",
   "metadata": {},
   "source": [
    "# LOOK AT EXTRACTING THE MISSCLASSIFIED IMAGES AND TALK ABOUT WHY THEY HAVE BEEN MISSCLASSIFIED (SIMILAR FEATURES, LOOKS LIKE A SUNSET ETC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2996cca1",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1305b06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 10:54:48.530566: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-26 10:54:48.530583: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-04-26 10:54:51.273946: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 10:54:51.274146: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:54:51.274202: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:54:51.274244: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:54:51.274282: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:54:51.274317: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:54:51.274353: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:54:51.274391: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:54:51.274430: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:54:51.274437: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-04-26 10:54:51.274712: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 381 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import functions\n",
    "data_dir = pathlib.Path('/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/data/Training and Validation')\n",
    "test_dir = pathlib.Path('/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/data/Testing')\n",
    "\n",
    "loaded_model = tf.keras.models.load_model('models/IA_model00_MobileNetv3_Small.h5')\n",
    "img_height, img_width, batch_size = [224, 224, 32]\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    shuffle = True,\n",
    "    seed = 89787,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'binary'\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8dac687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "figure has been saved to: /home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/plots/MobileNetV3_small/CM_IA_1_MobileNetV3_small.svg\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix, cm = functions.ConfusionMatrix(loaded_model, \n",
    "                                             test_ds, \n",
    "                                             save_fig = True, \n",
    "                                             save_fig_location = \"/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/plots/MobileNetV3_small/CM_IA_1_MobileNetV3_small.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493abdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions.CreateMetricsReport(model = loaded_model,\n",
    "                             dataset = test_ds,\n",
    "                             confusion_matrix = confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f2e891",
   "metadata": {},
   "source": [
    "## Testing on custom images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c087bfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import os\n",
    "import functions\n",
    "\n",
    "loaded_model = tf.keras.models.load_model('models/IA_model00_MobileNetv3_Small.h5')\n",
    "input_shape = (224, 224)\n",
    "img_directory = '/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/data/Photos-001/'\n",
    "\n",
    "test_preds = functions.TestImages(img_directory, input_shape, loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2c4eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in test_preds:\n",
    "    if i>0.5:\n",
    "        print(\"no fire\")\n",
    "    else:\n",
    "        count += 1\n",
    "        print(\"fire\")\n",
    "print('Incorrectly predicted ', count,  ' out of ',len(test_preds), '. FPR: ', round(count/len(test_preds), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c61a4f",
   "metadata": {},
   "source": [
    "## Testing on other dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6c84dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2204 files belonging to 2 classes.\n",
      "processing class directory  NoFire\n",
      "processing class directory  Fire\n",
      " no improper image files were found\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import functions\n",
    "\n",
    "data_dir = '../../data/Alt_dataset/Training Dataset'\n",
    "loaded_model = tf.keras.models.load_model('models/IA_model00_MobileNetv3_Small.h5')\n",
    "\n",
    "img_height, img_width, batch_size = [224, 224, 32] \n",
    "\n",
    "custom_test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    shuffle = True,\n",
    "    seed = 89787,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'binary'\n",
    "    )\n",
    "\n",
    "## Check if images are in the right format\n",
    "\n",
    "bad_file_list = functions.CheckImagesReport(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "641d8886",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Delete the incompatible files from the folder\n",
    "functions.DeleteIncompatibleImages(bad_file_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce001a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "figure has been saved to: /home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/plots/MobileNetV3_small/CM_IA_2_MobileNetV3_small.svg\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix, cm = functions.ConfusionMatrix(loaded_model, \n",
    "                                             custom_test_ds, \n",
    "                                             save_fig = True, \n",
    "                                             save_fig_location = \"/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/plots/MobileNetV3_small/CM_IA_2_MobileNetV3_small.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e0ce692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charlie/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 10s 133ms/step - loss: 0.3298 - precision: 0.9374 - recall: 0.8285 - auc: 0.9593\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.94465   0.84634   0.89280      1230\n",
      "           1    0.82849   0.93737   0.87958       974\n",
      "\n",
      "    accuracy                        0.88657      2204\n",
      "   macro avg    0.88657   0.89186   0.88619      2204\n",
      "weighted avg    0.89332   0.88657   0.88695      2204\n",
      "\n",
      "Test loss : 0.32984\n",
      "Test auc : 0.95928\n",
      "Test accuracy:  0.88657\n"
     ]
    }
   ],
   "source": [
    "functions.CreateMetricsReport(model = loaded_model,\n",
    "                             dataset = custom_test_ds,\n",
    "                             confusion_matrix = confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbb828d",
   "metadata": {},
   "source": [
    "# Feature map extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a019080d",
   "metadata": {},
   "source": [
    "from: https://towardsdatascience.com/convolutional-neural-network-feature-map-and-filter-visualization-f75012a5a49c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c75d1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = f'{test_dir}/nofire/abc191.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da11f676",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate thru all the layers of the model\n",
    "for layer in base_model.layers:\n",
    "    if 'conv' in layer.name:\n",
    "        weights = layer.get_weights()\n",
    "        print(weights)\n",
    "        \n",
    "        #normalize filter values between  0 and 1 for visualization\n",
    "        f_min, f_max = weights.min(), weights.max()\n",
    "        filters = (weights - f_min) / (f_max - f_min)  \n",
    "        print(filters.shape[3])\n",
    "        filter_cnt=1\n",
    "        \n",
    "        #plotting all the filters\n",
    "        for i in range(filters.shape[3]):\n",
    "            #get the filters\n",
    "            filt=filters[:,:,:, i]\n",
    "            #plotting each of the channel, color image RGB channels\n",
    "            for j in range(filters.shape[0]):\n",
    "                ax= plt.subplot(filters.shape[3], filters.shape[0], filter_cnt  )\n",
    "                ax.set_xticks([])\n",
    "                ax.set_yticks([])\n",
    "                plt.imshow(filt[:,:, j])\n",
    "                filter_cnt+=1\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82af638",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(model.layers[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568e86c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
