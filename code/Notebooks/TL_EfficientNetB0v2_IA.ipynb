{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "577a39f9",
   "metadata": {},
   "source": [
    "# Transfer Learning using EfficientNetB0 - Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7f5404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c533c7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir =pathlib.Path('/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/data/Training and Validation')\n",
    "test_dir =pathlib.Path('/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/data/Testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f486566",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d003e205",
   "metadata": {},
   "outputs": [],
   "source": [
    "fire = list(data_dir.glob('fire/*'))\n",
    "img = PIL.Image.open(str(fire[0]))\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337fab46",
   "metadata": {},
   "source": [
    "### Using Image Generator to load data into tf dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a9ef1c",
   "metadata": {},
   "source": [
    "Image input sizes: https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8956881",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    "# Validation split 80/20\n",
    "\n",
    "training_gen = ImageDataGenerator(horizontal_flip=True,\n",
    "                                  vertical_flip=True,\n",
    "                                  zoom_range=0.2,\n",
    "                                  width_shift_range=0.2,\n",
    "                                  height_shift_range=0.2,\n",
    "                                  brightness_range = (0.75, 1.25),\n",
    "                                  validation_split=0.2,\n",
    "                                  rotation_range = 30)\n",
    "\n",
    "\n",
    "train_ds = training_gen.flow_from_directory(data_dir, \n",
    "                                            target_size=(img_height, img_width), \n",
    "                                            color_mode = 'rgb',\n",
    "                                            class_mode='binary',\n",
    "                                            batch_size=batch_size,\n",
    "                                            subset='training')\n",
    "\n",
    "val_ds = training_gen.flow_from_directory(data_dir,\n",
    "                                            target_size=(img_height, img_width),\n",
    "                                            color_mode='rgb',\n",
    "                                            class_mode = 'binary',\n",
    "                                            batch_size=batch_size,\n",
    "                                            subset='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7875b4c2",
   "metadata": {},
   "source": [
    "## Seeing what augmentation is applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666705ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import expand_dims\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccdc526",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img(f'{data_dir}/fire/fire_0132.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f484f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "data = img_to_array(img)\n",
    "samples = expand_dims(data, 0)\n",
    "it = training_gen.flow(samples, batch_size=1)\n",
    "\n",
    "\n",
    "# generate samples and plot\n",
    "for i in range(3):\n",
    "\t# define subplot\n",
    "\tpyplot.figure(figsize=(25,25))\n",
    "pyplot.subplot(330 + 1+i)\n",
    "\t# generate batch of images\n",
    "batch = it.next()\n",
    "\t# convert to unsigned integers for viewing\n",
    "image = batch[0].astype('uint8')\n",
    "\t# plot raw pixel data\n",
    "pyplot.imshow(image)\n",
    "# show the figure\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203a9337",
   "metadata": {},
   "source": [
    "### Get Class Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eb59b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = list(train_ds.class_indices.keys())\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eacd4ec",
   "metadata": {},
   "source": [
    "### Create the base model from pre-trained convnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3848b9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## By specifying \"include_top=False\" argument you load a network that doesn't \n",
    "## include the classification layers at the top, which is ideal for feature extraction\n",
    "\n",
    "IMG_SHAPE = (img_width, img_height) + (3,)\n",
    "\n",
    "base_model = tf.keras.applications.EfficientNetB0(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=IMG_SHAPE,\n",
    "    classifier_activation=\"softmax\",\n",
    ")\n",
    "\n",
    "\n",
    "image_batch, label_batch = next(iter(train_ds))\n",
    "feature_batch = base_model(image_batch)\n",
    "print(feature_batch.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d556cb85",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9565031",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a588b0",
   "metadata": {},
   "source": [
    "## Add classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646d6dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "feature_batch_average = global_average_layer(feature_batch)\n",
    "print(feature_batch_average.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731a52e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_layer = tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "prediction_batch = prediction_layer(feature_batch_average)\n",
    "print(prediction_batch.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c14432",
   "metadata": {},
   "source": [
    "### Chain together the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434043f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape = (IMG_SHAPE))\n",
    "x = base_model(inputs, training = False)\n",
    "x = global_average_layer(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38854ac",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf891c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful metrics paper:\n",
    "# https://www.tensorflow.org/tutorials/structured_data/imbalanced_data\n",
    "\n",
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = base_learning_rate),\n",
    "              loss = tf.keras.losses.BinaryCrossentropy(from_logits=(True)),\n",
    "              metrics = [tf.keras.metrics.Precision(name = \"precision\"), tf.keras.metrics.Recall(name = \"recall\"),tf.keras.metrics.AUC(name = \"auc\")] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ecfa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e69fcf2",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cb8078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests the initial base model\n",
    "initial_epochs = 10\n",
    "loss0, precision0, recall0, auc0 = model.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23442254",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"initial loss: {:.2f}\".format(loss0))\n",
    "print(\"initial precision: {:.2f}\".format(precision0))\n",
    "print(\"initial recall: {:.2f}\".format(recall0))\n",
    "print(\"initial auc: {:.2f}\".format(auc0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddd5b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds,\n",
    "                    epochs = initial_epochs,\n",
    "                    validation_data = val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cf5555",
   "metadata": {},
   "source": [
    "### Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99220703",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = history.history['recall']\n",
    "val_recall = history.history['val_recall']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "auc = history.history['auc']\n",
    "val_auc = history.history['val_auc']\n",
    "\n",
    "precision = history.history['precision']\n",
    "val_pre = history.history['val_precision']\n",
    "\n",
    "plt.figure(figsize = (16, 16))\n",
    "plt.subplot(4, 2, 1)\n",
    "plt.plot(recall, label = 'Training Recall')\n",
    "plt.plot(val_recall, label='Validation Recall')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    shuffle = True,\n",
    "    seed = 123,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    "    )\n",
    "\n",
    "plt.subplot(4, 2, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(4, 2, 3)\n",
    "plt.plot(auc, label = 'Training AUC')\n",
    "plt.plot(val_auc, label='Validation AUC')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('AUC')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation AUC')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(4, 2, 4)\n",
    "plt.plot(precision, label = 'Training Precision')\n",
    "plt.plot(val_pre, label='Validation Precision')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Precision')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f6d61b",
   "metadata": {},
   "source": [
    "## Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc675c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previously the base model weights were not updated and only a few layers on top of the EfficientNetV2 was trained\n",
    "# Unfreeze and train the top layers of the pre-trained model to fine tune to the dataset\n",
    "\n",
    "## Un-freeze top layers of the model\n",
    "\n",
    "base_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e039116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look to see how many layers are in the base model\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30f4bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 100\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b78e384",
   "metadata": {},
   "source": [
    "### Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b60eb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Important to use a lower training weight since using more layers, otherwise\n",
    "# it could overfit very quickly \n",
    "\n",
    "model.compile(loss = tf.keras.losses.BinaryCrossentropy(from_logits = True),\n",
    "              optimizer = tf.keras.optimizers.RMSprop(learning_rate = base_learning_rate/10),\n",
    "              metrics = [tf.keras.metrics.Precision(name = \"precision\"), tf.keras.metrics.Recall(name = \"recall\"),tf.keras.metrics.AUC(name = \"auc\")])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d543d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(model.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238b6d3b",
   "metadata": {},
   "source": [
    "### Continue Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40db2745",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_epochs = 10\n",
    "total_epochs = initial_epochs + fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(train_ds,\n",
    "                         epochs = total_epochs,\n",
    "                         initial_epoch = history.epoch[-1],\n",
    "                         validation_data = val_ds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e306396",
   "metadata": {},
   "source": [
    "### Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf88e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall += history_fine.history['recall']\n",
    "val_recall += history_fine.history['val_recall']\n",
    "\n",
    "loss += history_fine.history['loss']\n",
    "val_loss += history_fine.history['val_loss']\n",
    "\n",
    "auc += history_fine.history['auc']\n",
    "val_auc += history_fine.history['val_auc']\n",
    "\n",
    "precision += history_fine.history['precision']\n",
    "val_pre += history_fine.history['val_precision']\n",
    "\n",
    "plt.figure(figsize = (16, 16))\n",
    "plt.subplot(4, 2, 1)\n",
    "plt.plot(recall, label = 'Training Recall')\n",
    "plt.plot(val_recall, label='Validation Recall')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.title('Training and Validation Recall')\n",
    "\n",
    "plt.subplot(4, 2, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(4, 2, 3)\n",
    "plt.plot(auc, label = 'Training AUC')\n",
    "plt.plot(val_auc, label='Validation AUC')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('AUC')\n",
    "plt.ylim([0.7,1.0])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.title('Training and Validation AUC')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(4, 2, 4)\n",
    "plt.plot(precision, label = 'Training Precision')\n",
    "plt.plot(val_pre, label='Validation Precision')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.7,1.0])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.title('Training and Validation Precision')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e96f150",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    shuffle = True,\n",
    "    seed = 123,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060cebc0",
   "metadata": {},
   "source": [
    "## Testing on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396da123",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, precision, recall, auc = model.evaluate(test_ds)\n",
    "print('Test loss :', loss)\n",
    "print('Test precision :', precision)\n",
    "print('Test recall :', recall)\n",
    "print('Test auc :', auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74a4318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve a batch of images from the test set\n",
    "image_batch, label_batch = test_ds.as_numpy_iterator().next()\n",
    "predictions = model.predict_on_batch(image_batch).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955702b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.round(predictions, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41597eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fc5570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve a batch of images from the test set\n",
    "image_batch, label_batch = test_ds.as_numpy_iterator().next()\n",
    "predictions = model.predict_on_batch(image_batch).flatten()\n",
    "\n",
    "# pred = model.predict(test_ds)\n",
    "# pred = np.argmax(pred, axis = 1)[:5]\n",
    "# label = \n",
    "\n",
    "# Apply a sigmoid since our model returns logits\n",
    "#predictions = tf.nn.sigmoid(predictions)\n",
    "predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "\n",
    "print('Predictions:\\n', predictions.numpy())\n",
    "print('Labels:\\n', label_batch)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "  ax = plt.subplot(3, 3, i + 1)\n",
    "  plt.imshow(image_batch[i].astype(\"uint8\"))\n",
    "  plt.title(class_names[predictions[i]])\n",
    "  plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa5fa78",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8011e171",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/IA_model00_EfficientNetB0.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469bd300",
   "metadata": {},
   "source": [
    "# LOOK AT EXTRACTING THE MISSCLASSIFIED IMAGES AND TALK ABOUT WHY THEY HAVE BEEN MISSCLASSIFIED (SIMILAR FEATURES, LOOKS LIKE A SUNSET ETC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2996cca1",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3a06007",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 10:30:03.471824: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-26 10:30:03.471842: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-04-26 10:30:05.378318: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 10:30:05.378487: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:30:05.378524: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:30:05.378557: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:30:05.378588: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:30:05.378617: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:30:05.378645: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:30:05.378675: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:30:05.378706: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:30:05.378711: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-04-26 10:30:05.378883: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 381 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import functions\n",
    "\n",
    "data_dir = pathlib.Path('/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/data/Training and Validation')\n",
    "test_dir = pathlib.Path('/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/data/Testing')\n",
    "\n",
    "loaded_model = tf.keras.models.load_model('models/IA_model00_EfficientNetB0.h5')\n",
    "img_height, img_width, batch_size = [224, 224, 32]\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    shuffle = True,\n",
    "    seed = 89787,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'binary'\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26cb0f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "figure has been saved to: /home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/plots/CM_IA_1_EfficientNetB0.svg\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix, cm = functions.ConfusionMatrix(loaded_model, \n",
    "                                             test_ds, \n",
    "                                             save_fig = True, \n",
    "                                             save_fig_location = \"/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/plots/CM_IA_1_EfficientNetB0.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9534aa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions.CreateMetricsReport(model = loaded_model,\n",
    "                             dataset = test_ds,\n",
    "                             confusion_matrix = confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a63ab7",
   "metadata": {},
   "source": [
    "## Testing on custom images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73655c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import os\n",
    "import functions\n",
    "\n",
    "loaded_model = tf.keras.models.load_model('models/IA_model00_EfficientNetB0.h5')\n",
    "input_shape = (224, 224)\n",
    "img_directory = '/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/data/Photos-001/'\n",
    "\n",
    "test_preds = functions.TestImages(img_directory, input_shape, loaded_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e73947",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in test_preds:\n",
    "    if i>0.5:\n",
    "        print(\"no fire\")\n",
    "    else:\n",
    "        count += 1\n",
    "        print(\"fire\")\n",
    "print('Incorrectly predicted ', count,  ' out of ',len(test_preds), '. FPR: ', round(count/len(test_preds), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9672f5e",
   "metadata": {},
   "source": [
    "## Testing on other dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14e43a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2204 files belonging to 2 classes.\n",
      "processing class directory  NoFire\n",
      "processing class directory  Fire\n",
      " no improper image files were found\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import functions\n",
    "\n",
    "data_dir = '../../data/Alt_dataset/Training Dataset'\n",
    "loaded_model = tf.keras.models.load_model('models/IA_model00_EfficientNetB0.h5')\n",
    "\n",
    "img_height, img_width, batch_size = [224, 224, 32] \n",
    "\n",
    "\n",
    "custom_test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    shuffle = True,\n",
    "    seed = 89787,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'binary'\n",
    "    )\n",
    "\n",
    "## Check if images are in the right format\n",
    "\n",
    "bad_file_list = functions.CheckImagesReport(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "612806f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No incompatible files\n"
     ]
    }
   ],
   "source": [
    "## Delete the incompatible files from the folder\n",
    "if bad_file_list:\n",
    "    functions.DeleteIncompatibleImages(bad_file_list)\n",
    "else:\n",
    "    print(\"No incompatible files\")\n",
    "\n",
    "functions.DeleteIncompatibleImages(bad_file_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc93657f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "figure has been saved to: /home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/plots/CM_IA_2_EfficientNetB0.svg\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix, cm = functions.ConfusionMatrix(loaded_model, \n",
    "                                             custom_test_ds, \n",
    "                                             save_fig = True, \n",
    "                                             save_fig_location = \"/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/plots/CM_IA_2_EfficientNetB0.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a4a9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions.CreateMetricsReport(model = loaded_model,\n",
    "                             dataset = custom_test_ds,\n",
    "                             confusion_matrix = confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5953a9a",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9aed12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
