{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "577a39f9",
   "metadata": {},
   "source": [
    "# Transfer Learning using MobileNetV3_Small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7f5404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c533c7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir =pathlib.Path('/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/data/Training and Validation')\n",
    "test_dir =pathlib.Path('/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/data/Testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f486566",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d003e205",
   "metadata": {},
   "outputs": [],
   "source": [
    "fire = list(data_dir.glob('fire/*'))\n",
    "img = PIL.Image.open(str(fire[0]))\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337fab46",
   "metadata": {},
   "source": [
    "### Load data into a tf dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a9ef1c",
   "metadata": {},
   "source": [
    "Image input sizes: https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8956881",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    "# Validation split 80/20\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split = 0.2,\n",
    "    subset = \"training\",\n",
    "    shuffle = True,\n",
    "    seed = 123,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf95709",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split = 0.2,\n",
    "    subset = \"validation\",\n",
    "    shuffle = True,\n",
    "    seed = 123,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size    \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eeac62",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    shuffle = True,\n",
    "    seed = 123,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203a9337",
   "metadata": {},
   "source": [
    "### Get Class Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eb59b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2982e2fd",
   "metadata": {},
   "source": [
    "### Visualise Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8406f3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89d6dac",
   "metadata": {},
   "source": [
    "### Configure the dataset for performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73585ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.prefetch(buffer_size = AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(buffer_size = AUTOTUNE)\n",
    "test_ds = test_ds.prefetch(buffer_size = AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eacd4ec",
   "metadata": {},
   "source": [
    "### Create the base model from pre-trained convnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3848b9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## By specifying \"include_top=False\" argument you load a network that doesn't \n",
    "## include the classification layers at the top, which is ideal for feature extraction\n",
    "\n",
    "IMG_SHAPE = (img_width, img_height) + (3,)\n",
    "\n",
    "base_model = tf.keras.applications.MobileNetV3Small(\n",
    "    input_shape=IMG_SHAPE,\n",
    "    alpha=1.0,\n",
    "    minimalistic=False,\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_tensor=None,\n",
    "    pooling=None,\n",
    "    dropout_rate=0.2,\n",
    "    classifier_activation='softmax',\n",
    "    include_preprocessing=True\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "image_batch, label_batch = next(iter(train_ds))\n",
    "feature_batch = base_model(image_batch)\n",
    "print(feature_batch.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d556cb85",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9565031",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a588b0",
   "metadata": {},
   "source": [
    "## Add classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646d6dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "feature_batch_average = global_average_layer(feature_batch)\n",
    "print(feature_batch_average.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731a52e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_layer = tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "prediction_batch = prediction_layer(feature_batch_average)\n",
    "print(prediction_batch.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c14432",
   "metadata": {},
   "source": [
    "### Chain together the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434043f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape = (IMG_SHAPE))\n",
    "x = base_model(inputs, training = False)\n",
    "x = global_average_layer(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38854ac",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf891c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful metrics paper:\n",
    "# https://www.tensorflow.org/tutorials/structured_data/imbalanced_data\n",
    "\n",
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = base_learning_rate),\n",
    "              loss = tf.keras.losses.BinaryCrossentropy(from_logits=(True)),\n",
    "              metrics = [tf.keras.metrics.Precision(name = \"precision\"), tf.keras.metrics.Recall(name = \"recall\"),tf.keras.metrics.AUC(name = \"auc\")] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ecfa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e69fcf2",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cb8078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests the initial base model\n",
    "initial_epochs = 10\n",
    "loss0, precision0, recall0, auc0 = model.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23442254",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"initial loss: {:.2f}\".format(loss0))\n",
    "print(\"initial precision: {:.2f}\".format(precision0))\n",
    "print(\"initial recall: {:.2f}\".format(recall0))\n",
    "print(\"initial auc: {:.2f}\".format(auc0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddd5b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds,\n",
    "                    epochs = initial_epochs,\n",
    "                    validation_data = val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cf5555",
   "metadata": {},
   "source": [
    "### Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99220703",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = history.history['recall']\n",
    "val_recall = history.history['val_recall']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "auc = history.history['auc']\n",
    "val_auc = history.history['val_auc']\n",
    "\n",
    "precision = history.history['precision']\n",
    "val_pre = history.history['val_precision']\n",
    "\n",
    "plt.figure(figsize = (16, 16))\n",
    "plt.subplot(4, 2, 1)\n",
    "plt.plot(recall, label = 'Training Recall')\n",
    "plt.plot(val_recall, label='Validation Recall')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    shuffle = True,\n",
    "    seed = 123,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    "    )\n",
    "\n",
    "plt.subplot(4, 2, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(4, 2, 3)\n",
    "plt.plot(auc, label = 'Training AUC')\n",
    "plt.plot(val_auc, label='Validation AUC')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('AUC')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation AUC')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(4, 2, 4)\n",
    "plt.plot(precision, label = 'Training Precision')\n",
    "plt.plot(val_pre, label='Validation Precision')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Precision')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f6d61b",
   "metadata": {},
   "source": [
    "## Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc675c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previously the base model weights were not updated and only a few layers on top of the EfficientNetV2 was trained\n",
    "# Unfreeze and train the top layers of the pre-trained model to fine tune to the dataset\n",
    "\n",
    "## Un-freeze top layers of the model\n",
    "\n",
    "base_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e039116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look to see how many layers are in the base model\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30f4bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 100\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b78e384",
   "metadata": {},
   "source": [
    "### Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b60eb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Important to use a lower training weight since using more layers, otherwise\n",
    "# it could overfit very quickly \n",
    "\n",
    "model.compile(loss = tf.keras.losses.BinaryCrossentropy(from_logits = True),\n",
    "              optimizer = tf.keras.optimizers.RMSprop(learning_rate = base_learning_rate/10),\n",
    "              metrics = [tf.keras.metrics.Precision(name = \"precision\"), \n",
    "                         tf.keras.metrics.Recall(name = \"recall\"),\n",
    "                         tf.keras.metrics.AUC(name = \"auc\")])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d543d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(model.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238b6d3b",
   "metadata": {},
   "source": [
    "### Continue Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40db2745",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_epochs = 10\n",
    "total_epochs = initial_epochs + fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(train_ds,\n",
    "                         epochs = total_epochs,\n",
    "                         initial_epoch = history.epoch[-1],\n",
    "                         validation_data = val_ds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e306396",
   "metadata": {},
   "source": [
    "### Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf88e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall += history_fine.history['recall']\n",
    "val_recall += history_fine.history['val_recall']\n",
    "\n",
    "loss += history_fine.history['loss']\n",
    "val_loss += history_fine.history['val_loss']\n",
    "\n",
    "auc += history_fine.history['auc']\n",
    "val_auc += history_fine.history['val_auc']\n",
    "\n",
    "precision += history_fine.history['precision']\n",
    "val_pre += history_fine.history['val_precision']\n",
    "\n",
    "plt.figure(figsize = (16, 16))\n",
    "plt.subplot(4, 2, 1)\n",
    "plt.plot(recall, label = 'Training Recall')\n",
    "plt.plot(val_recall, label='Validation Recall')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.title('Training and Validation Recall')\n",
    "\n",
    "plt.subplot(4, 2, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(4, 2, 3)\n",
    "plt.plot(auc, label = 'Training AUC')\n",
    "plt.plot(val_auc, label='Validation AUC')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('AUC')\n",
    "plt.ylim([0.7,1.0])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.title('Training and Validation AUC')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(4, 2, 4)\n",
    "plt.plot(precision, label = 'Training Precision')\n",
    "plt.plot(val_pre, label='Validation Precision')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.7,1.0])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.title('Training and Validation Precision')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e96f150",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    shuffle = True,\n",
    "    seed = 123,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    "    )\n",
    "\n",
    "\n",
    "test_ds = test_ds.prefetch(buffer_size = AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060cebc0",
   "metadata": {},
   "source": [
    "## Verifying on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396da123",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, precision, recall, auc = model.evaluate(test_ds)\n",
    "print('Test loss :', loss)\n",
    "print('Test precision :', precision)\n",
    "print('Test recall :', recall)\n",
    "print('Test auc :', auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74a4318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve a batch of images from the test set\n",
    "image_batch, label_batch = test_ds.as_numpy_iterator().next()\n",
    "predictions = model.predict_on_batch(image_batch).flatten()\n",
    "\n",
    "# pred = model.predict(test_ds)\n",
    "# pred = np.argmax(pred, axis = 1)[:5]\n",
    "# label = \n",
    "\n",
    "# Apply a sigmoid since our model returns logits\n",
    "#predictions = tf.nn.sigmoid(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955702b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.round(predictions, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41597eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fc5570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve a batch of images from the test set\n",
    "image_batch, label_batch = test_ds.as_numpy_iterator().next()\n",
    "predictions = model.predict_on_batch(image_batch).flatten()\n",
    "\n",
    "# pred = model.predict(test_ds)\n",
    "# pred = np.argmax(pred, axis = 1)[:5]\n",
    "# label = \n",
    "\n",
    "# Apply a sigmoid since our model returns logits\n",
    "#predictions = tf.nn.sigmoid(predictions)\n",
    "predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "\n",
    "print('Predictions:\\n', predictions.numpy())\n",
    "print('Labels:\\n', label_batch)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "  ax = plt.subplot(3, 3, i + 1)\n",
    "  plt.imshow(image_batch[i].astype(\"uint8\"))\n",
    "  plt.title(class_names[predictions[i]])\n",
    "  plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffc499e",
   "metadata": {},
   "source": [
    "## Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9615b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model00_MobileNetv3_Small.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469bd300",
   "metadata": {},
   "source": [
    "# LOOK AT EXTRACTING THE MISSCLASSIFIED IMAGES AND TALK ABOUT WHY THEY HAVE BEEN MISSCLASSIFIED (SIMILAR FEATURES, LOOKS LIKE A SUNSET ETC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2996cca1",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1305b06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-23 12:15:05.614036: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-23 12:15:05.614091: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-04-23 12:15:11.968671: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-23 12:15:11.969422: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-23 12:15:11.969547: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-23 12:15:11.969651: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-23 12:15:11.969751: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-23 12:15:11.969847: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-23 12:15:11.969942: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-23 12:15:11.970037: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-23 12:15:11.970135: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-23 12:15:11.970152: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-04-23 12:15:11.970660: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 381 files belonging to 2 classes.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import functions\n",
    "data_dir = pathlib.Path('/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/data/Training and Validation')\n",
    "test_dir = pathlib.Path('/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/data/Testing')\n",
    "\n",
    "loaded_model = tf.keras.models.load_model('models/model00_MobileNetv3_Small.h5')\n",
    "img_height, img_width, batch_size = [224, 224, 32]\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    shuffle = True,\n",
    "    seed = 89787,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'binary'\n",
    "    )\n",
    "\n",
    "confusion_matrix = functions.ConfusionMatrix(loaded_model, test_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a52ac924",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charlie/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 4s 156ms/step - loss: 0.0748 - precision: 0.9689 - recall: 0.9791 - auc: 0.9979\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.96842   0.97872   0.97354       188\n",
      "           1    0.97906   0.96891   0.97396       193\n",
      "\n",
      "    accuracy                        0.97375       381\n",
      "   macro avg    0.97374   0.97382   0.97375       381\n",
      "weighted avg    0.97381   0.97375   0.97375       381\n",
      "\n",
      "Test loss : 0.07478\n",
      "Test auc : 0.99791\n",
      "Test accuracy:  0.97375\n"
     ]
    }
   ],
   "source": [
    "functions.CreateMetricsReport(model = loaded_model,\n",
    "                             dataset = test_ds,\n",
    "                             confusion_matrix = confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f2e891",
   "metadata": {},
   "source": [
    "## Testing on custom images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c087bfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import os\n",
    "import functions\n",
    "\n",
    "loaded_model = tf.keras.models.load_model('models/model00_MobileNetv3_Small.h5')\n",
    "input_shape = (224, 224)\n",
    "img_directory = '/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/data/Photos-001/'\n",
    "\n",
    "test_preds = functions.TestImages(img_directory, input_shape, loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2c4eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in test_preds:\n",
    "    if i>0.5:\n",
    "        print(\"no fire\")\n",
    "    else:\n",
    "        count += 1\n",
    "        print(\"fire\")\n",
    "print('Incorrectly predicted ', count,  ' out of ',len(test_preds), '. FPR: ', round(count/len(test_preds), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc8bcca",
   "metadata": {},
   "source": [
    "## Testing on other dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a93d3b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2204 files belonging to 2 classes.\n",
      "processing class directory  NoFire\n",
      "processing class directory  Fire\n",
      " no improper image files were found\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import functions\n",
    "\n",
    "data_dir = '../../data/Alt_dataset/Training Dataset'\n",
    "loaded_model = tf.keras.models.load_model('models/model00_MobileNetv3_Small.h5')\n",
    "\n",
    "img_height, img_width, batch_size = [224, 224, 32] \n",
    "\n",
    "custom_test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    shuffle = True,\n",
    "    seed = 89787,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'binary'\n",
    "    )\n",
    "\n",
    "## Check if images are in the right format\n",
    "\n",
    "bad_file_list = functions.CheckImagesReport(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "984b9f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fire', 'NoFire']\n"
     ]
    }
   ],
   "source": [
    "print(custom_test_ds.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "641d8886",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Delete the incompatible files from the folder\n",
    "functions.DeleteIncompatibleImages(bad_file_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce001a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_matrix = functions.ConfusionMatrix(loaded_model, custom_test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18fa0a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charlie/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 18s 207ms/step - loss: 0.4231 - precision: 0.9186 - recall: 0.8394 - auc: 0.9453\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.92559   0.85213   0.88734      1197\n",
      "           1    0.83938   0.91857   0.87719      1007\n",
      "\n",
      "    accuracy                        0.88249      2204\n",
      "   macro avg    0.88249   0.88535   0.88227      2204\n",
      "weighted avg    0.88620   0.88249   0.88271      2204\n",
      "\n",
      "Test loss : 0.4231\n",
      "Test auc : 0.94533\n",
      "Test accuracy:  0.88249\n"
     ]
    }
   ],
   "source": [
    "functions.CreateMetricsReport(model = loaded_model,\n",
    "                             dataset = custom_test_ds,\n",
    "                             confusion_matrix = confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbb828d",
   "metadata": {},
   "source": [
    "# Feature map extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a019080d",
   "metadata": {},
   "source": [
    "from: https://towardsdatascience.com/convolutional-neural-network-feature-map-and-filter-visualization-f75012a5a49c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c75d1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = f'{test_dir}/nofire/abc191.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da11f676",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate thru all the layers of the model\n",
    "for layer in base_model.layers:\n",
    "    if 'conv' in layer.name:\n",
    "        weights = layer.get_weights()\n",
    "        print(weights)\n",
    "        \n",
    "        #normalize filter values between  0 and 1 for visualization\n",
    "        f_min, f_max = weights.min(), weights.max()\n",
    "        filters = (weights - f_min) / (f_max - f_min)  \n",
    "        print(filters.shape[3])\n",
    "        filter_cnt=1\n",
    "        \n",
    "        #plotting all the filters\n",
    "        for i in range(filters.shape[3]):\n",
    "            #get the filters\n",
    "            filt=filters[:,:,:, i]\n",
    "            #plotting each of the channel, color image RGB channels\n",
    "            for j in range(filters.shape[0]):\n",
    "                ax= plt.subplot(filters.shape[3], filters.shape[0], filter_cnt  )\n",
    "                ax.set_xticks([])\n",
    "                ax.set_yticks([])\n",
    "                plt.imshow(filt[:,:, j])\n",
    "                filter_cnt+=1\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82af638",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(model.layers[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568e86c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
