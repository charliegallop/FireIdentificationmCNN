{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "577a39f9",
   "metadata": {},
   "source": [
    "# Transfer Learning using EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7f5404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c533c7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir =pathlib.Path('/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/data/Training and Validation')\n",
    "test_dir =pathlib.Path('/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/data/Testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f486566",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d003e205",
   "metadata": {},
   "outputs": [],
   "source": [
    "fire = list(data_dir.glob('fire/*'))\n",
    "img = PIL.Image.open(str(fire[0]))\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337fab46",
   "metadata": {},
   "source": [
    "### Load data into a tf dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a9ef1c",
   "metadata": {},
   "source": [
    "Image input sizes: https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8956881",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    "# Validation split 80/20\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split = 0.2,\n",
    "    subset = \"training\",\n",
    "    shuffle = True,\n",
    "    seed = 123,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf95709",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split = 0.2,\n",
    "    subset = \"validation\",\n",
    "    shuffle = True,\n",
    "    seed = 123,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size    \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eeac62",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    shuffle = True,\n",
    "    seed = 123,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203a9337",
   "metadata": {},
   "source": [
    "### Get Class Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eb59b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2982e2fd",
   "metadata": {},
   "source": [
    "### Visualise Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8406f3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89d6dac",
   "metadata": {},
   "source": [
    "### Configure the dataset for performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73585ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.prefetch(buffer_size = AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(buffer_size = AUTOTUNE)\n",
    "test_ds = test_ds.prefetch(buffer_size = AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eacd4ec",
   "metadata": {},
   "source": [
    "### Create the base model from pre-trained convnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3848b9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## By specifying \"include_top=False\" argument you load a network that doesn't \n",
    "## include the classification layers at the top, which is ideal for feature extraction\n",
    "\n",
    "IMG_SHAPE = (img_width, img_height) + (3,)\n",
    "\n",
    "base_model = tf.keras.applications.EfficientNetB0(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=IMG_SHAPE,\n",
    "    classifier_activation=\"softmax\",\n",
    ")\n",
    "\n",
    "\n",
    "image_batch, label_batch = next(iter(train_ds))\n",
    "feature_batch = base_model(image_batch)\n",
    "print(feature_batch.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d556cb85",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9565031",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a588b0",
   "metadata": {},
   "source": [
    "## Add classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646d6dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "feature_batch_average = global_average_layer(feature_batch)\n",
    "print(feature_batch_average.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731a52e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_layer = tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "prediction_batch = prediction_layer(feature_batch_average)\n",
    "print(prediction_batch.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c14432",
   "metadata": {},
   "source": [
    "### Chain together the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434043f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape = (IMG_SHAPE))\n",
    "x = base_model(inputs, training = False)\n",
    "x = global_average_layer(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38854ac",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf891c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful metrics paper:\n",
    "# https://www.tensorflow.org/tutorials/structured_data/imbalanced_data\n",
    "\n",
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = base_learning_rate),\n",
    "              loss = tf.keras.losses.BinaryCrossentropy(from_logits=(True)),\n",
    "              metrics = [tf.keras.metrics.Precision(name = \"precision\"), tf.keras.metrics.Recall(name = \"recall\"),tf.keras.metrics.AUC(name = \"auc\")] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ecfa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e69fcf2",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cb8078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests the initial base model\n",
    "initial_epochs = 10\n",
    "loss0, precision0, recall0, auc0 = model.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23442254",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"initial loss: {:.2f}\".format(loss0))\n",
    "print(\"initial precision: {:.2f}\".format(precision0))\n",
    "print(\"initial recall: {:.2f}\".format(recall0))\n",
    "print(\"initial auc: {:.2f}\".format(auc0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddd5b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds,\n",
    "                    epochs = initial_epochs,\n",
    "                    validation_data = val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cf5555",
   "metadata": {},
   "source": [
    "### Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99220703",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = history.history['recall']\n",
    "val_recall = history.history['val_recall']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "auc = history.history['auc']\n",
    "val_auc = history.history['val_auc']\n",
    "\n",
    "precision = history.history['precision']\n",
    "val_pre = history.history['val_precision']\n",
    "\n",
    "plt.figure(figsize = (16, 16))\n",
    "plt.subplot(4, 2, 1)\n",
    "plt.plot(recall, label = 'Training Recall')\n",
    "plt.plot(val_recall, label='Validation Recall')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    shuffle = True,\n",
    "    seed = 123,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    "    )\n",
    "\n",
    "plt.subplot(4, 2, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(4, 2, 3)\n",
    "plt.plot(auc, label = 'Training AUC')\n",
    "plt.plot(val_auc, label='Validation AUC')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('AUC')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation AUC')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(4, 2, 4)\n",
    "plt.plot(precision, label = 'Training Precision')\n",
    "plt.plot(val_pre, label='Validation Precision')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Precision')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f6d61b",
   "metadata": {},
   "source": [
    "## Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc675c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previously the base model weights were not updated and only a few layers on top of the EfficientNetV2 was trained\n",
    "# Unfreeze and train the top layers of the pre-trained model to fine tune to the dataset\n",
    "\n",
    "## Un-freeze top layers of the model\n",
    "\n",
    "base_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e039116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look to see how many layers are in the base model\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30f4bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 100\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b78e384",
   "metadata": {},
   "source": [
    "### Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b60eb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Important to use a lower training weight since using more layers, otherwise\n",
    "# it could overfit very quickly \n",
    "\n",
    "model.compile(loss = tf.keras.losses.BinaryCrossentropy(from_logits = True),\n",
    "              optimizer = tf.keras.optimizers.RMSprop(learning_rate = base_learning_rate/10),\n",
    "              metrics = [tf.keras.metrics.Precision(name = \"precision\"), tf.keras.metrics.Recall(name = \"recall\"),tf.keras.metrics.AUC(name = \"auc\")])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d543d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(model.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238b6d3b",
   "metadata": {},
   "source": [
    "### Continue Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40db2745",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_epochs = 10\n",
    "total_epochs = initial_epochs + fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(train_ds,\n",
    "                         epochs = total_epochs,\n",
    "                         initial_epoch = history.epoch[-1],\n",
    "                         validation_data = val_ds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e306396",
   "metadata": {},
   "source": [
    "### Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf88e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall += history_fine.history['recall']\n",
    "val_recall += history_fine.history['val_recall']\n",
    "\n",
    "loss += history_fine.history['loss']\n",
    "val_loss += history_fine.history['val_loss']\n",
    "\n",
    "auc += history_fine.history['auc']\n",
    "val_auc += history_fine.history['val_auc']\n",
    "\n",
    "precision += history_fine.history['precision']\n",
    "val_pre += history_fine.history['val_precision']\n",
    "\n",
    "plt.figure(figsize = (16, 16))\n",
    "plt.subplot(4, 2, 1)\n",
    "plt.plot(recall, label = 'Training Recall')\n",
    "plt.plot(val_recall, label='Validation Recall')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.title('Training and Validation Recall')\n",
    "\n",
    "plt.subplot(4, 2, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(4, 2, 3)\n",
    "plt.plot(auc, label = 'Training AUC')\n",
    "plt.plot(val_auc, label='Validation AUC')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('AUC')\n",
    "plt.ylim([0.7,1.0])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.title('Training and Validation AUC')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(4, 2, 4)\n",
    "plt.plot(precision, label = 'Training Precision')\n",
    "plt.plot(val_pre, label='Validation Precision')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.7,1.0])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.title('Training and Validation Precision')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e96f150",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    shuffle = True,\n",
    "    seed = 123,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    "    )\n",
    "\n",
    "\n",
    "test_ds = test_ds.prefetch(buffer_size = AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060cebc0",
   "metadata": {},
   "source": [
    "## Testing on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396da123",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, precision, recall, auc = model.evaluate(test_ds)\n",
    "print('Test loss :', loss)\n",
    "print('Test precision :', precision)\n",
    "print('Test recall :', recall)\n",
    "print('Test auc :', auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74a4318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve a batch of images from the test set\n",
    "image_batch, label_batch = test_ds.as_numpy_iterator().next()\n",
    "predictions = model.predict_on_batch(image_batch).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955702b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.round(predictions, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41597eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fc5570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve a batch of images from the test set\n",
    "image_batch, label_batch = test_ds.as_numpy_iterator().next()\n",
    "predictions = model.predict_on_batch(image_batch).flatten()\n",
    "\n",
    "# pred = model.predict(test_ds)\n",
    "# pred = np.argmax(pred, axis = 1)[:5]\n",
    "# label = \n",
    "\n",
    "# Apply a sigmoid since our model returns logits\n",
    "#predictions = tf.nn.sigmoid(predictions)\n",
    "predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "\n",
    "print('Predictions:\\n', predictions.numpy())\n",
    "print('Labels:\\n', label_batch)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "  ax = plt.subplot(3, 3, i + 1)\n",
    "  plt.imshow(image_batch[i].astype(\"uint8\"))\n",
    "  plt.title(class_names[predictions[i]])\n",
    "  plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa5fa78",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8011e171",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model00_EfficientNetB0.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469bd300",
   "metadata": {},
   "source": [
    "# LOOK AT EXTRACTING THE MISSCLASSIFIED IMAGES AND TALK ABOUT WHY THEY HAVE BEEN MISSCLASSIFIED (SIMILAR FEATURES, LOOKS LIKE A SUNSET ETC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2996cca1",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3a06007",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 10:26:57.625812: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-26 10:26:57.625829: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-04-26 10:26:59.551059: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 10:26:59.551228: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:26:59.551266: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:26:59.551299: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:26:59.551330: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:26:59.551360: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:26:59.551390: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:26:59.551421: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:26:59.551451: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:26:59.551458: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-04-26 10:26:59.551675: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 381 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import functions\n",
    "\n",
    "data_dir = pathlib.Path('/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/data/Training and Validation')\n",
    "test_dir = pathlib.Path('/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/data/Testing')\n",
    "\n",
    "loaded_model = tf.keras.models.load_model('models/model00_EfficientNetB0.h5')\n",
    "img_height, img_width, batch_size = [224, 224, 32]\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    shuffle = True,\n",
    "    seed = 89787,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'binary'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7efb52e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "figure has been saved to: /home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/plots/CM_NO_IA_1_EfficientNetB0.svg\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix, cm = functions.ConfusionMatrix(loaded_model, \n",
    "                                             test_ds, \n",
    "                                             save_fig = True, \n",
    "                                             save_fig_location = \"/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/plots/CM_NO_IA_1_EfficientNetB0.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc554da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions.CreateMetricsReport(model = loaded_model,\n",
    "                             dataset = test_ds,\n",
    "                             confusion_matrix = confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a63ab7",
   "metadata": {},
   "source": [
    "## Testing on custom images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73655c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import os\n",
    "import functions\n",
    "\n",
    "loaded_model = tf.keras.models.load_model('models/model00_EfficientNetB0.h5')\n",
    "input_shape = (224, 224)\n",
    "img_directory = '/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/data/Photos-001/'\n",
    "\n",
    "test_preds = functions.TestImages(img_directory, input_shape, loaded_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e73947",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in test_preds:\n",
    "    if i>0.5:\n",
    "        print(\"no fire\")\n",
    "    else:\n",
    "        count += 1\n",
    "        print(\"fire\")\n",
    "print('Incorrectly predicted ', count,  ' out of ',len(test_preds), '. FPR: ', round(count/len(test_preds), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9672f5e",
   "metadata": {},
   "source": [
    "## Testing on other dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14e43a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2204 files belonging to 2 classes.\n",
      "processing class directory  NoFire\n",
      "processing class directory  Fire\n",
      " no improper image files were found\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import functions\n",
    "\n",
    "data_dir = '../../data/Alt_dataset/Training Dataset'\n",
    "loaded_model = tf.keras.models.load_model('models/model00_EfficientNetB0.h5')\n",
    "\n",
    "img_height, img_width, batch_size = [224, 224, 32] \n",
    "\n",
    "\n",
    "data_dir = '../../data/Alt_dataset/Training Dataset'\n",
    "loaded_model = tf.keras.models.load_model('models/model00_EfficientNetB0.h5')\n",
    "\n",
    "img_height, img_width, batch_size = [224, 224, 32] \n",
    "\n",
    "custom_test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    shuffle = True,\n",
    "    seed = 89787,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'binary'\n",
    "    )\n",
    "\n",
    "## Check if images are in the right format\n",
    "\n",
    "bad_file_list = functions.CheckImagesReport(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "612806f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No incompatible files\n"
     ]
    }
   ],
   "source": [
    "## Delete the incompatible files from the folder\n",
    "if bad_file_list:\n",
    "    functions.DeleteIncompatibleImages(bad_file_list)\n",
    "else:\n",
    "    print(\"No incompatible files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc93657f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "figure has been saved to: /home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/plots/CM_NO_IA_2_EfficientNetB0.svg\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix, cm = functions.ConfusionMatrix(loaded_model, \n",
    "                                             custom_test_ds, \n",
    "                                             save_fig = True, \n",
    "                                             save_fig_location = \"/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/plots/CM_NO_IA_2_EfficientNetB0.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8f4c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions.CreateMetricsReport(model = loaded_model,\n",
    "                             dataset = custom_test_ds,\n",
    "                             confusion_matrix = confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5953a9a",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9aed12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d7fba4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
