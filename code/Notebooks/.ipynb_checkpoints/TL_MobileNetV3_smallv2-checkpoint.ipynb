{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "577a39f9",
   "metadata": {},
   "source": [
    "# Transfer Learning using MobileNetV3_Small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7f5404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c533c7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir =pathlib.Path('/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/data/Training and Validation')\n",
    "test_dir =pathlib.Path('/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/data/Testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f486566",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d003e205",
   "metadata": {},
   "outputs": [],
   "source": [
    "fire = list(data_dir.glob('fire/*'))\n",
    "img = PIL.Image.open(str(fire[0]))\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337fab46",
   "metadata": {},
   "source": [
    "### Load data into a tf dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a9ef1c",
   "metadata": {},
   "source": [
    "Image input sizes: https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8956881",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    "# Validation split 80/20\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split = 0.2,\n",
    "    subset = \"training\",\n",
    "    shuffle = True,\n",
    "    seed = 123,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf95709",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split = 0.2,\n",
    "    subset = \"validation\",\n",
    "    shuffle = True,\n",
    "    seed = 123,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size    \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eeac62",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    shuffle = True,\n",
    "    seed = 123,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203a9337",
   "metadata": {},
   "source": [
    "### Get Class Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eb59b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2982e2fd",
   "metadata": {},
   "source": [
    "### Visualise Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8406f3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89d6dac",
   "metadata": {},
   "source": [
    "### Configure the dataset for performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73585ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.prefetch(buffer_size = AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(buffer_size = AUTOTUNE)\n",
    "test_ds = test_ds.prefetch(buffer_size = AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eacd4ec",
   "metadata": {},
   "source": [
    "### Create the base model from pre-trained convnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3848b9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## By specifying \"include_top=False\" argument you load a network that doesn't \n",
    "## include the classification layers at the top, which is ideal for feature extraction\n",
    "\n",
    "IMG_SHAPE = (img_width, img_height) + (3,)\n",
    "\n",
    "base_model = tf.keras.applications.MobileNetV3Small(\n",
    "    input_shape=IMG_SHAPE,\n",
    "    alpha=1.0,\n",
    "    minimalistic=False,\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_tensor=None,\n",
    "    pooling=None,\n",
    "    dropout_rate=0.2,\n",
    "    classifier_activation='softmax',\n",
    "    include_preprocessing=True\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "image_batch, label_batch = next(iter(train_ds))\n",
    "feature_batch = base_model(image_batch)\n",
    "print(feature_batch.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d556cb85",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9565031",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a588b0",
   "metadata": {},
   "source": [
    "## Add classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646d6dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "feature_batch_average = global_average_layer(feature_batch)\n",
    "print(feature_batch_average.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731a52e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_layer = tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "prediction_batch = prediction_layer(feature_batch_average)\n",
    "print(prediction_batch.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c14432",
   "metadata": {},
   "source": [
    "### Chain together the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434043f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape = (IMG_SHAPE))\n",
    "x = base_model(inputs, training = False)\n",
    "x = global_average_layer(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38854ac",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf891c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful metrics paper:\n",
    "# https://www.tensorflow.org/tutorials/structured_data/imbalanced_data\n",
    "\n",
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = base_learning_rate),\n",
    "              loss = tf.keras.losses.BinaryCrossentropy(from_logits=(True)),\n",
    "              metrics = [tf.keras.metrics.Precision(name = \"precision\"), tf.keras.metrics.Recall(name = \"recall\"),tf.keras.metrics.AUC(name = \"auc\")] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ecfa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e69fcf2",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cb8078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests the initial base model\n",
    "initial_epochs = 10\n",
    "loss0, precision0, recall0, auc0 = model.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23442254",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"initial loss: {:.2f}\".format(loss0))\n",
    "print(\"initial precision: {:.2f}\".format(precision0))\n",
    "print(\"initial recall: {:.2f}\".format(recall0))\n",
    "print(\"initial auc: {:.2f}\".format(auc0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddd5b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds,\n",
    "                    epochs = initial_epochs,\n",
    "                    validation_data = val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cf5555",
   "metadata": {},
   "source": [
    "### Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99220703",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = history.history['recall']\n",
    "val_recall = history.history['val_recall']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "auc = history.history['auc']\n",
    "val_auc = history.history['val_auc']\n",
    "\n",
    "precision = history.history['precision']\n",
    "val_pre = history.history['val_precision']\n",
    "\n",
    "plt.figure(figsize = (16, 16))\n",
    "plt.subplot(4, 2, 1)\n",
    "plt.plot(recall, label = 'Training Recall')\n",
    "plt.plot(val_recall, label='Validation Recall')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    shuffle = True,\n",
    "    seed = 123,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    "    )\n",
    "\n",
    "plt.subplot(4, 2, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(4, 2, 3)\n",
    "plt.plot(auc, label = 'Training AUC')\n",
    "plt.plot(val_auc, label='Validation AUC')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('AUC')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation AUC')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(4, 2, 4)\n",
    "plt.plot(precision, label = 'Training Precision')\n",
    "plt.plot(val_pre, label='Validation Precision')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Precision')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f6d61b",
   "metadata": {},
   "source": [
    "## Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc675c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previously the base model weights were not updated and only a few layers on top of the EfficientNetV2 was trained\n",
    "# Unfreeze and train the top layers of the pre-trained model to fine tune to the dataset\n",
    "\n",
    "## Un-freeze top layers of the model\n",
    "\n",
    "base_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e039116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look to see how many layers are in the base model\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30f4bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 100\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b78e384",
   "metadata": {},
   "source": [
    "### Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b60eb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Important to use a lower training weight since using more layers, otherwise\n",
    "# it could overfit very quickly \n",
    "\n",
    "model.compile(loss = tf.keras.losses.BinaryCrossentropy(from_logits = True),\n",
    "              optimizer = tf.keras.optimizers.RMSprop(learning_rate = base_learning_rate/10),\n",
    "              metrics = [tf.keras.metrics.Precision(name = \"precision\"), tf.keras.metrics.Recall(name = \"recall\"),tf.keras.metrics.AUC(name = \"auc\")])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d543d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(model.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238b6d3b",
   "metadata": {},
   "source": [
    "### Continue Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40db2745",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_epochs = 10\n",
    "total_epochs = initial_epochs + fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(train_ds,\n",
    "                         epochs = total_epochs,\n",
    "                         initial_epoch = history.epoch[-1],\n",
    "                         validation_data = val_ds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e306396",
   "metadata": {},
   "source": [
    "### Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf88e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall += history_fine.history['recall']\n",
    "val_recall += history_fine.history['val_recall']\n",
    "\n",
    "loss += history_fine.history['loss']\n",
    "val_loss += history_fine.history['val_loss']\n",
    "\n",
    "auc += history_fine.history['auc']\n",
    "val_auc += history_fine.history['val_auc']\n",
    "\n",
    "precision += history_fine.history['precision']\n",
    "val_pre += history_fine.history['val_precision']\n",
    "\n",
    "plt.figure(figsize = (16, 16))\n",
    "plt.subplot(4, 2, 1)\n",
    "plt.plot(recall, label = 'Training Recall')\n",
    "plt.plot(val_recall, label='Validation Recall')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.title('Training and Validation Recall')\n",
    "\n",
    "plt.subplot(4, 2, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(4, 2, 3)\n",
    "plt.plot(auc, label = 'Training AUC')\n",
    "plt.plot(val_auc, label='Validation AUC')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('AUC')\n",
    "plt.ylim([0.7,1.0])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.title('Training and Validation AUC')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(4, 2, 4)\n",
    "plt.plot(precision, label = 'Training Precision')\n",
    "plt.plot(val_pre, label='Validation Precision')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.7,1.0])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.title('Training and Validation Precision')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e96f150",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    shuffle = True,\n",
    "    seed = 123,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    "    )\n",
    "\n",
    "\n",
    "test_ds = test_ds.prefetch(buffer_size = AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060cebc0",
   "metadata": {},
   "source": [
    "## Verifying on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396da123",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, precision, recall, auc = model.evaluate(test_ds)\n",
    "print('Test loss :', loss)\n",
    "print('Test precision :', precision)\n",
    "print('Test recall :', recall)\n",
    "print('Test auc :', auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74a4318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve a batch of images from the test set\n",
    "image_batch, label_batch = test_ds.as_numpy_iterator().next()\n",
    "predictions = model.predict_on_batch(image_batch).flatten()\n",
    "\n",
    "# pred = model.predict(test_ds)\n",
    "# pred = np.argmax(pred, axis = 1)[:5]\n",
    "# label = \n",
    "\n",
    "# Apply a sigmoid since our model returns logits\n",
    "#predictions = tf.nn.sigmoid(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955702b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.round(predictions, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41597eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fc5570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve a batch of images from the test set\n",
    "image_batch, label_batch = test_ds.as_numpy_iterator().next()\n",
    "predictions = model.predict_on_batch(image_batch).flatten()\n",
    "\n",
    "# pred = model.predict(test_ds)\n",
    "# pred = np.argmax(pred, axis = 1)[:5]\n",
    "# label = \n",
    "\n",
    "# Apply a sigmoid since our model returns logits\n",
    "#predictions = tf.nn.sigmoid(predictions)\n",
    "predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "\n",
    "print('Predictions:\\n', predictions.numpy())\n",
    "print('Labels:\\n', label_batch)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "  ax = plt.subplot(3, 3, i + 1)\n",
    "  plt.imshow(image_batch[i].astype(\"uint8\"))\n",
    "  plt.title(class_names[predictions[i]])\n",
    "  plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffc499e",
   "metadata": {},
   "source": [
    "## Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9615b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model00_MobileNetv3_Small.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469bd300",
   "metadata": {},
   "source": [
    "# LOOK AT EXTRACTING THE MISSCLASSIFIED IMAGES AND TALK ABOUT WHY THEY HAVE BEEN MISSCLASSIFIED (SIMILAR FEATURES, LOOKS LIKE A SUNSET ETC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2996cca1",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1305b06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-23 11:10:34.989335: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-23 11:10:34.989380: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-04-23 11:10:41.288960: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-23 11:10:41.289454: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-23 11:10:41.289577: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-23 11:10:41.289686: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-23 11:10:41.289781: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-23 11:10:41.289874: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-23 11:10:41.290002: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-23 11:10:41.290106: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-23 11:10:41.290226: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-23 11:10:41.290244: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-04-23 11:10:41.290909: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 381 files belonging to 2 classes.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import functions\n",
    "data_dir = pathlib.Path('/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/data/Training and Validation')\n",
    "test_dir = pathlib.Path('/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/data/Testing')\n",
    "\n",
    "loaded_model = tf.keras.models.load_model('models/model00_MobileNetv3_Small.h5')\n",
    "img_height, img_width, batch_size = [224, 224, 32]\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    shuffle = True,\n",
    "    seed = 89787,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'binary'\n",
    "    )\n",
    "\n",
    "confusion_matrix = functions.ConfusionMatrix(loaded_model, test_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "497827ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charlie/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 4s 154ms/step - loss: 0.0748 - precision: 0.9689 - recall: 0.9791 - auc: 0.9979\n",
      "Test loss : 0.07478159666061401\n",
      "Test precision : 0.9689119458198547\n",
      "Test recall : 0.9790576100349426\n",
      "Test auc : 0.9979057908058167\n",
      "Test accuracy:  0.973753280839895\n",
      "Test F1 Score:  0.9739583569543255\n"
     ]
    }
   ],
   "source": [
    "loss, precision, recall, auc = loaded_model.evaluate(test_ds)\n",
    "print('Test loss :', loss)\n",
    "print('Test precision :', precision)\n",
    "print('Test recall :', recall)\n",
    "print('Test auc :', auc)\n",
    "print('Test accuracy: ', functions.CalculateAccuracy(confusion_matrix))\n",
    "print('Test F1 Score: ', functions.CalculateF1Score(precision, recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f2e891",
   "metadata": {},
   "source": [
    "## Testing on custom images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c087bfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import os\n",
    "import functions\n",
    "\n",
    "loaded_model = tf.keras.models.load_model('models/model00_MobileNetv3_Small.h5')\n",
    "input_shape = (224, 224)\n",
    "img_directory = '/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/data/Photos-001/'\n",
    "\n",
    "test_preds = functions.TestImages(img_directory, input_shape, loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2c4eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in test_preds:\n",
    "    if i>0.5:\n",
    "        print(\"no fire\")\n",
    "    else:\n",
    "        count += 1\n",
    "        print(\"fire\")\n",
    "print('Incorrectly predicted ', count,  ' out of ',len(test_preds), '. FPR: ', round(count/len(test_preds), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc8bcca",
   "metadata": {},
   "source": [
    "## Testing on other dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a93d3b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2204 files belonging to 2 classes.\n",
      "processing class directory  NoFire\n",
      "processing class directory  Fire\n",
      " no improper image files were found\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import functions\n",
    "\n",
    "data_dir = '../../data/Alt_dataset/Training Dataset'\n",
    "loaded_model = tf.keras.models.load_model('models/model00_MobileNetv3_Small.h5')\n",
    "\n",
    "img_height, img_width, batch_size = [224, 224, 32] \n",
    "\n",
    "custom_test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    shuffle = True,\n",
    "    seed = 89787,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'binary'\n",
    "    )\n",
    "\n",
    "## Check if images are in the right format\n",
    "\n",
    "bad_file_list = functions.CheckImagesReport(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "984b9f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fire', 'NoFire']\n"
     ]
    }
   ],
   "source": [
    "print(custom_test_ds.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "641d8886",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Delete the incompatible files from the folder\n",
    "functions.DeleteIncompatibleImages(bad_file_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce001a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "functions.ConfusionMatrix(loaded_model, custom_test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18fa0a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 16s 207ms/step - loss: 0.4231 - precision: 0.9186 - recall: 0.8394 - auc: 0.9453\n",
      "Test loss : 0.42309561371803284\n",
      "Test precision : 0.9185699820518494\n",
      "Test recall : 0.8393829464912415\n",
      "Test auc : 0.9453321099281311\n"
     ]
    }
   ],
   "source": [
    "loss, precision, recall, auc = loaded_model.evaluate(custom_test_ds)\n",
    "print('Test loss :', loss)\n",
    "print('Test precision :', precision)\n",
    "print('Test recall :', recall)\n",
    "print('Test auc :', auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbb828d",
   "metadata": {},
   "source": [
    "# Feature map extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a019080d",
   "metadata": {},
   "source": [
    "from: https://towardsdatascience.com/convolutional-neural-network-feature-map-and-filter-visualization-f75012a5a49c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c75d1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = f'{test_dir}/nofire/abc191.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da11f676",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate thru all the layers of the model\n",
    "for layer in base_model.layers:\n",
    "    if 'conv' in layer.name:\n",
    "        weights = layer.get_weights()\n",
    "        print(weights)\n",
    "        \n",
    "        #normalize filter values between  0 and 1 for visualization\n",
    "        f_min, f_max = weights.min(), weights.max()\n",
    "        filters = (weights - f_min) / (f_max - f_min)  \n",
    "        print(filters.shape[3])\n",
    "        filter_cnt=1\n",
    "        \n",
    "        #plotting all the filters\n",
    "        for i in range(filters.shape[3]):\n",
    "            #get the filters\n",
    "            filt=filters[:,:,:, i]\n",
    "            #plotting each of the channel, color image RGB channels\n",
    "            for j in range(filters.shape[0]):\n",
    "                ax= plt.subplot(filters.shape[3], filters.shape[0], filter_cnt  )\n",
    "                ax.set_xticks([])\n",
    "                ax.set_yticks([])\n",
    "                plt.imshow(filt[:,:, j])\n",
    "                filter_cnt+=1\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82af638",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(model.layers[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568e86c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
