{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "577a39f9",
   "metadata": {},
   "source": [
    "# Transfer Learning using EfficientNetB0 - Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7f5404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c533c7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir =pathlib.Path('/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/data/Training and Validation')\n",
    "test_dir =pathlib.Path('/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/data/Testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f486566",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d003e205",
   "metadata": {},
   "outputs": [],
   "source": [
    "fire = list(data_dir.glob('fire/*'))\n",
    "img = PIL.Image.open(str(fire[0]))\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337fab46",
   "metadata": {},
   "source": [
    "### Using Image Generator to load data into tf dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a9ef1c",
   "metadata": {},
   "source": [
    "Image input sizes: https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8956881",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    "# Validation split 80/20\n",
    "\n",
    "training_gen = ImageDataGenerator(horizontal_flip=True,\n",
    "                                  vertical_flip=True,\n",
    "                                  zoom_range=0.2,\n",
    "                                  width_shift_range=0.2,\n",
    "                                  height_shift_range=0.2,\n",
    "                                  brightness_range = (0.75, 1.25),\n",
    "                                  validation_split=0.2,\n",
    "                                  rotation_range = 30)\n",
    "\n",
    "\n",
    "train_ds = training_gen.flow_from_directory(data_dir, \n",
    "                                            target_size=(img_height, img_width), \n",
    "                                            color_mode = 'rgb',\n",
    "                                            class_mode='binary',\n",
    "                                            batch_size=batch_size,\n",
    "                                            subset='training')\n",
    "\n",
    "val_ds = training_gen.flow_from_directory(data_dir,\n",
    "                                            target_size=(img_height, img_width),\n",
    "                                            color_mode='rgb',\n",
    "                                            class_mode = 'binary',\n",
    "                                            batch_size=batch_size,\n",
    "                                            subset='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7875b4c2",
   "metadata": {},
   "source": [
    "## Seeing what augmentation is applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666705ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import expand_dims\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccdc526",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img(f'{data_dir}/fire/fire_0132.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f484f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "data = img_to_array(img)\n",
    "samples = expand_dims(data, 0)\n",
    "it = training_gen.flow(samples, batch_size=1)\n",
    "\n",
    "\n",
    "# generate samples and plot\n",
    "for i in range(3):\n",
    "\t# define subplot\n",
    "\tpyplot.figure(figsize=(25,25))\n",
    "pyplot.subplot(330 + 1+i)\n",
    "\t# generate batch of images\n",
    "batch = it.next()\n",
    "\t# convert to unsigned integers for viewing\n",
    "image = batch[0].astype('uint8')\n",
    "\t# plot raw pixel data\n",
    "pyplot.imshow(image)\n",
    "# show the figure\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203a9337",
   "metadata": {},
   "source": [
    "### Get Class Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eb59b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = list(train_ds.class_indices.keys())\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eacd4ec",
   "metadata": {},
   "source": [
    "### Create the base model from pre-trained convnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3848b9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## By specifying \"include_top=False\" argument you load a network that doesn't \n",
    "## include the classification layers at the top, which is ideal for feature extraction\n",
    "\n",
    "IMG_SHAPE = (img_width, img_height) + (3,)\n",
    "\n",
    "base_model = tf.keras.applications.EfficientNetB0(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=IMG_SHAPE,\n",
    "    classifier_activation=\"softmax\",\n",
    ")\n",
    "\n",
    "\n",
    "image_batch, label_batch = next(iter(train_ds))\n",
    "feature_batch = base_model(image_batch)\n",
    "print(feature_batch.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d556cb85",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9565031",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a588b0",
   "metadata": {},
   "source": [
    "## Add classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646d6dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "feature_batch_average = global_average_layer(feature_batch)\n",
    "print(feature_batch_average.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731a52e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_layer = tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "prediction_batch = prediction_layer(feature_batch_average)\n",
    "print(prediction_batch.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c14432",
   "metadata": {},
   "source": [
    "### Chain together the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434043f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape = (IMG_SHAPE))\n",
    "x = base_model(inputs, training = False)\n",
    "x = global_average_layer(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38854ac",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf891c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful metrics paper:\n",
    "# https://www.tensorflow.org/tutorials/structured_data/imbalanced_data\n",
    "\n",
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = base_learning_rate),\n",
    "              loss = tf.keras.losses.BinaryCrossentropy(from_logits=(True)),\n",
    "              metrics = [tf.keras.metrics.Precision(name = \"precision\"), tf.keras.metrics.Recall(name = \"recall\"),tf.keras.metrics.AUC(name = \"auc\")] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ecfa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e69fcf2",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cb8078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests the initial base model\n",
    "initial_epochs = 10\n",
    "loss0, precision0, recall0, auc0 = model.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23442254",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"initial loss: {:.2f}\".format(loss0))\n",
    "print(\"initial precision: {:.2f}\".format(precision0))\n",
    "print(\"initial recall: {:.2f}\".format(recall0))\n",
    "print(\"initial auc: {:.2f}\".format(auc0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddd5b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds,\n",
    "                    epochs = initial_epochs,\n",
    "                    validation_data = val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cf5555",
   "metadata": {},
   "source": [
    "### Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99220703",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = history.history['recall']\n",
    "val_recall = history.history['val_recall']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "auc = history.history['auc']\n",
    "val_auc = history.history['val_auc']\n",
    "\n",
    "precision = history.history['precision']\n",
    "val_pre = history.history['val_precision']\n",
    "\n",
    "plt.figure(figsize = (16, 16))\n",
    "plt.subplot(4, 2, 1)\n",
    "plt.plot(recall, label = 'Training Recall')\n",
    "plt.plot(val_recall, label='Validation Recall')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    shuffle = True,\n",
    "    seed = 123,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    "    )\n",
    "\n",
    "plt.subplot(4, 2, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(4, 2, 3)\n",
    "plt.plot(auc, label = 'Training AUC')\n",
    "plt.plot(val_auc, label='Validation AUC')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('AUC')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation AUC')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(4, 2, 4)\n",
    "plt.plot(precision, label = 'Training Precision')\n",
    "plt.plot(val_pre, label='Validation Precision')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Precision')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f6d61b",
   "metadata": {},
   "source": [
    "## Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc675c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previously the base model weights were not updated and only a few layers on top of the EfficientNetV2 was trained\n",
    "# Unfreeze and train the top layers of the pre-trained model to fine tune to the dataset\n",
    "\n",
    "## Un-freeze top layers of the model\n",
    "\n",
    "base_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e039116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look to see how many layers are in the base model\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30f4bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 100\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b78e384",
   "metadata": {},
   "source": [
    "### Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b60eb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Important to use a lower training weight since using more layers, otherwise\n",
    "# it could overfit very quickly \n",
    "\n",
    "model.compile(loss = tf.keras.losses.BinaryCrossentropy(from_logits = True),\n",
    "              optimizer = tf.keras.optimizers.RMSprop(learning_rate = base_learning_rate/10),\n",
    "              metrics = [tf.keras.metrics.Precision(name = \"precision\"), tf.keras.metrics.Recall(name = \"recall\"),tf.keras.metrics.AUC(name = \"auc\")])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d543d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(model.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238b6d3b",
   "metadata": {},
   "source": [
    "### Continue Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40db2745",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_epochs = 10\n",
    "total_epochs = initial_epochs + fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(train_ds,\n",
    "                         epochs = total_epochs,\n",
    "                         initial_epoch = history.epoch[-1],\n",
    "                         validation_data = val_ds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e306396",
   "metadata": {},
   "source": [
    "### Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf88e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall += history_fine.history['recall']\n",
    "val_recall += history_fine.history['val_recall']\n",
    "\n",
    "loss += history_fine.history['loss']\n",
    "val_loss += history_fine.history['val_loss']\n",
    "\n",
    "auc += history_fine.history['auc']\n",
    "val_auc += history_fine.history['val_auc']\n",
    "\n",
    "precision += history_fine.history['precision']\n",
    "val_pre += history_fine.history['val_precision']\n",
    "\n",
    "plt.figure(figsize = (16, 16))\n",
    "plt.subplot(4, 2, 1)\n",
    "plt.plot(recall, label = 'Training Recall')\n",
    "plt.plot(val_recall, label='Validation Recall')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.title('Training and Validation Recall')\n",
    "\n",
    "plt.subplot(4, 2, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(4, 2, 3)\n",
    "plt.plot(auc, label = 'Training AUC')\n",
    "plt.plot(val_auc, label='Validation AUC')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('AUC')\n",
    "plt.ylim([0.7,1.0])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.title('Training and Validation AUC')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(4, 2, 4)\n",
    "plt.plot(precision, label = 'Training Precision')\n",
    "plt.plot(val_pre, label='Validation Precision')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.7,1.0])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.title('Training and Validation Precision')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e96f150",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    shuffle = True,\n",
    "    seed = 123,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060cebc0",
   "metadata": {},
   "source": [
    "## Testing on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396da123",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, precision, recall, auc = model.evaluate(test_ds)\n",
    "print('Test loss :', loss)\n",
    "print('Test precision :', precision)\n",
    "print('Test recall :', recall)\n",
    "print('Test auc :', auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74a4318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve a batch of images from the test set\n",
    "image_batch, label_batch = test_ds.as_numpy_iterator().next()\n",
    "predictions = model.predict_on_batch(image_batch).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955702b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.round(predictions, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41597eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fc5570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve a batch of images from the test set\n",
    "image_batch, label_batch = test_ds.as_numpy_iterator().next()\n",
    "predictions = model.predict_on_batch(image_batch).flatten()\n",
    "\n",
    "# pred = model.predict(test_ds)\n",
    "# pred = np.argmax(pred, axis = 1)[:5]\n",
    "# label = \n",
    "\n",
    "# Apply a sigmoid since our model returns logits\n",
    "#predictions = tf.nn.sigmoid(predictions)\n",
    "predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "\n",
    "print('Predictions:\\n', predictions.numpy())\n",
    "print('Labels:\\n', label_batch)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "  ax = plt.subplot(3, 3, i + 1)\n",
    "  plt.imshow(image_batch[i].astype(\"uint8\"))\n",
    "  plt.title(class_names[predictions[i]])\n",
    "  plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa5fa78",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8011e171",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/IA_model00_EfficientNetB0.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469bd300",
   "metadata": {},
   "source": [
    "# LOOK AT EXTRACTING THE MISSCLASSIFIED IMAGES AND TALK ABOUT WHY THEY HAVE BEEN MISSCLASSIFIED (SIMILAR FEATURES, LOOKS LIKE A SUNSET ETC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2996cca1",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3a06007",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 10:18:18.530789: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-26 10:18:18.530807: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-04-26 10:18:20.475954: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 10:18:20.476139: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:18:20.476181: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:18:20.476217: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:18:20.476250: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:18:20.476285: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:18:20.476317: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:18:20.476349: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:18:20.476382: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:18:20.476389: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-04-26 10:18:20.476540: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 381 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import functions\n",
    "\n",
    "data_dir = pathlib.Path('/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/data/Training and Validation')\n",
    "test_dir = pathlib.Path('/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/data/Testing')\n",
    "\n",
    "loaded_model = tf.keras.models.load_model('models/IA_model00_EfficientNetB0.h5')\n",
    "img_height, img_width, batch_size = [224, 224, 32]\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    shuffle = True,\n",
    "    seed = 89787,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'binary'\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26cb0f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "figure has been saved to: /home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/plots/CM_IA_1_EfficientNetB0.png\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix, cm = functions.ConfusionMatrix(loaded_model, \n",
    "                                             test_ds, \n",
    "                                             save_fig = True, \n",
    "                                             save_fig_location = \"/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/plots/CM_IA_1_EfficientNetB0.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9534aa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions.CreateMetricsReport(model = loaded_model,\n",
    "                             dataset = test_ds,\n",
    "                             confusion_matrix = confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a63ab7",
   "metadata": {},
   "source": [
    "## Testing on custom images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73655c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import os\n",
    "import functions\n",
    "\n",
    "loaded_model = tf.keras.models.load_model('models/IA_model00_EfficientNetB0.h5')\n",
    "input_shape = (224, 224)\n",
    "img_directory = '/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/data/Photos-001/'\n",
    "\n",
    "test_preds = functions.TestImages(img_directory, input_shape, loaded_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e73947",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in test_preds:\n",
    "    if i>0.5:\n",
    "        print(\"no fire\")\n",
    "    else:\n",
    "        count += 1\n",
    "        print(\"fire\")\n",
    "print('Incorrectly predicted ', count,  ' out of ',len(test_preds), '. FPR: ', round(count/len(test_preds), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9672f5e",
   "metadata": {},
   "source": [
    "## Testing on other dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e43a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import functions\n",
    "\n",
    "data_dir = '../../data/Alt_dataset/Training Dataset'\n",
    "loaded_model = tf.keras.models.load_model('models/IA_model00_EfficientNetB0.h5')\n",
    "\n",
    "img_height, img_width, batch_size = [224, 224, 32] \n",
    "\n",
    "\n",
    "custom_test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    shuffle = True,\n",
    "    seed = 89787,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'binary'\n",
    "    )\n",
    "\n",
    "## Check if images are in the right format\n",
    "\n",
    "bad_file_list = functions.CheckImagesReport(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612806f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Delete the incompatible files from the folder\n",
    "if bad_file_list:\n",
    "    functions.DeleteIncompatibleImages(bad_file_list)\n",
    "else:\n",
    "    print(\"No incompatible files\")\n",
    "\n",
    "functions.DeleteIncompatibleImages(bad_file_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc93657f",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix, cm = functions.ConfusionMatrix(loaded_model, \n",
    "                                             custom_test_ds, \n",
    "                                             save_fig = True, \n",
    "                                             save_fig_location = \"/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/plots/CM_IA_2_EfficientNetB0.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a4a9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions.CreateMetricsReport(model = loaded_model,\n",
    "                             dataset = custom_test_ds,\n",
    "                             confusion_matrix = confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5953a9a",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9aed12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
