{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "577a39f9",
   "metadata": {},
   "source": [
    "# Transfer Learning using EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7f5404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c533c7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir =pathlib.Path('/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/data/Training and Validation')\n",
    "test_dir =pathlib.Path('/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/data/Testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f486566",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d003e205",
   "metadata": {},
   "outputs": [],
   "source": [
    "fire = list(data_dir.glob('fire/*'))\n",
    "img = PIL.Image.open(str(fire[0]))\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337fab46",
   "metadata": {},
   "source": [
    "### Load data into a tf dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a9ef1c",
   "metadata": {},
   "source": [
    "Image input sizes: https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8956881",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    "# Validation split 80/20\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split = 0.2,\n",
    "    subset = \"training\",\n",
    "    shuffle = True,\n",
    "    seed = 123,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf95709",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split = 0.2,\n",
    "    subset = \"validation\",\n",
    "    shuffle = True,\n",
    "    seed = 123,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size    \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eeac62",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    shuffle = True,\n",
    "    seed = 123,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203a9337",
   "metadata": {},
   "source": [
    "### Get Class Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eb59b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2982e2fd",
   "metadata": {},
   "source": [
    "### Visualise Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8406f3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89d6dac",
   "metadata": {},
   "source": [
    "### Configure the dataset for performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73585ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.prefetch(buffer_size = AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(buffer_size = AUTOTUNE)\n",
    "test_ds = test_ds.prefetch(buffer_size = AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eacd4ec",
   "metadata": {},
   "source": [
    "### Create the base model from pre-trained convnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3848b9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## By specifying \"include_top=False\" argument you load a network that doesn't \n",
    "## include the classification layers at the top, which is ideal for feature extraction\n",
    "\n",
    "IMG_SHAPE = (img_width, img_height) + (3,)\n",
    "\n",
    "base_model = tf.keras.applications.EfficientNetB0(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=IMG_SHAPE,\n",
    "    classifier_activation=\"softmax\",\n",
    ")\n",
    "\n",
    "\n",
    "image_batch, label_batch = next(iter(train_ds))\n",
    "feature_batch = base_model(image_batch)\n",
    "print(feature_batch.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d556cb85",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9565031",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a588b0",
   "metadata": {},
   "source": [
    "## Add classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646d6dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "feature_batch_average = global_average_layer(feature_batch)\n",
    "print(feature_batch_average.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731a52e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_layer = tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "prediction_batch = prediction_layer(feature_batch_average)\n",
    "print(prediction_batch.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c14432",
   "metadata": {},
   "source": [
    "### Chain together the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434043f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape = (IMG_SHAPE))\n",
    "x = base_model(inputs, training = False)\n",
    "x = global_average_layer(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38854ac",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf891c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful metrics paper:\n",
    "# https://www.tensorflow.org/tutorials/structured_data/imbalanced_data\n",
    "\n",
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = base_learning_rate),\n",
    "              loss = tf.keras.losses.BinaryCrossentropy(from_logits=(True)),\n",
    "              metrics = [tf.keras.metrics.Precision(name = \"precision\"), tf.keras.metrics.Recall(name = \"recall\"),tf.keras.metrics.AUC(name = \"auc\")] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ecfa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e69fcf2",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cb8078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests the initial base model\n",
    "initial_epochs = 10\n",
    "loss0, precision0, recall0, auc0 = model.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23442254",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"initial loss: {:.2f}\".format(loss0))\n",
    "print(\"initial precision: {:.2f}\".format(precision0))\n",
    "print(\"initial recall: {:.2f}\".format(recall0))\n",
    "print(\"initial auc: {:.2f}\".format(auc0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddd5b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds,\n",
    "                    epochs = initial_epochs,\n",
    "                    validation_data = val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cf5555",
   "metadata": {},
   "source": [
    "### Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99220703",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = history.history['recall']\n",
    "val_recall = history.history['val_recall']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "auc = history.history['auc']\n",
    "val_auc = history.history['val_auc']\n",
    "\n",
    "precision = history.history['precision']\n",
    "val_pre = history.history['val_precision']\n",
    "\n",
    "plt.figure(figsize = (16, 16))\n",
    "plt.subplot(4, 2, 1)\n",
    "plt.plot(recall, label = 'Training Recall')\n",
    "plt.plot(val_recall, label='Validation Recall')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    shuffle = True,\n",
    "    seed = 123,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    "    )\n",
    "\n",
    "plt.subplot(4, 2, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(4, 2, 3)\n",
    "plt.plot(auc, label = 'Training AUC')\n",
    "plt.plot(val_auc, label='Validation AUC')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('AUC')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation AUC')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(4, 2, 4)\n",
    "plt.plot(precision, label = 'Training Precision')\n",
    "plt.plot(val_pre, label='Validation Precision')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Precision')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f6d61b",
   "metadata": {},
   "source": [
    "## Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc675c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previously the base model weights were not updated and only a few layers on top of the EfficientNetV2 was trained\n",
    "# Unfreeze and train the top layers of the pre-trained model to fine tune to the dataset\n",
    "\n",
    "## Un-freeze top layers of the model\n",
    "\n",
    "base_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e039116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look to see how many layers are in the base model\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30f4bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 100\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b78e384",
   "metadata": {},
   "source": [
    "### Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b60eb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Important to use a lower training weight since using more layers, otherwise\n",
    "# it could overfit very quickly \n",
    "\n",
    "model.compile(loss = tf.keras.losses.BinaryCrossentropy(from_logits = True),\n",
    "              optimizer = tf.keras.optimizers.RMSprop(learning_rate = base_learning_rate/10),\n",
    "              metrics = [tf.keras.metrics.Precision(name = \"precision\"), tf.keras.metrics.Recall(name = \"recall\"),tf.keras.metrics.AUC(name = \"auc\")])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d543d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(model.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238b6d3b",
   "metadata": {},
   "source": [
    "### Continue Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40db2745",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_epochs = 10\n",
    "total_epochs = initial_epochs + fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(train_ds,\n",
    "                         epochs = total_epochs,\n",
    "                         initial_epoch = history.epoch[-1],\n",
    "                         validation_data = val_ds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e306396",
   "metadata": {},
   "source": [
    "### Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf88e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall += history_fine.history['recall']\n",
    "val_recall += history_fine.history['val_recall']\n",
    "\n",
    "loss += history_fine.history['loss']\n",
    "val_loss += history_fine.history['val_loss']\n",
    "\n",
    "auc += history_fine.history['auc']\n",
    "val_auc += history_fine.history['val_auc']\n",
    "\n",
    "precision += history_fine.history['precision']\n",
    "val_pre += history_fine.history['val_precision']\n",
    "\n",
    "plt.figure(figsize = (16, 16))\n",
    "plt.subplot(4, 2, 1)\n",
    "plt.plot(recall, label = 'Training Recall')\n",
    "plt.plot(val_recall, label='Validation Recall')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.title('Training and Validation Recall')\n",
    "\n",
    "plt.subplot(4, 2, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(4, 2, 3)\n",
    "plt.plot(auc, label = 'Training AUC')\n",
    "plt.plot(val_auc, label='Validation AUC')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('AUC')\n",
    "plt.ylim([0.7,1.0])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.title('Training and Validation AUC')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(4, 2, 4)\n",
    "plt.plot(precision, label = 'Training Precision')\n",
    "plt.plot(val_pre, label='Validation Precision')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.7,1.0])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.title('Training and Validation Precision')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e96f150",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    shuffle = True,\n",
    "    seed = 123,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    "    )\n",
    "\n",
    "\n",
    "test_ds = test_ds.prefetch(buffer_size = AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060cebc0",
   "metadata": {},
   "source": [
    "## Testing on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396da123",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, precision, recall, auc = model.evaluate(test_ds)\n",
    "print('Test loss :', loss)\n",
    "print('Test precision :', precision)\n",
    "print('Test recall :', recall)\n",
    "print('Test auc :', auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74a4318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve a batch of images from the test set\n",
    "image_batch, label_batch = test_ds.as_numpy_iterator().next()\n",
    "predictions = model.predict_on_batch(image_batch).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955702b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.round(predictions, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41597eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fc5570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve a batch of images from the test set\n",
    "image_batch, label_batch = test_ds.as_numpy_iterator().next()\n",
    "predictions = model.predict_on_batch(image_batch).flatten()\n",
    "\n",
    "# pred = model.predict(test_ds)\n",
    "# pred = np.argmax(pred, axis = 1)[:5]\n",
    "# label = \n",
    "\n",
    "# Apply a sigmoid since our model returns logits\n",
    "#predictions = tf.nn.sigmoid(predictions)\n",
    "predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "\n",
    "print('Predictions:\\n', predictions.numpy())\n",
    "print('Labels:\\n', label_batch)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "  ax = plt.subplot(3, 3, i + 1)\n",
    "  plt.imshow(image_batch[i].astype(\"uint8\"))\n",
    "  plt.title(class_names[predictions[i]])\n",
    "  plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa5fa78",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8011e171",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model00_EfficientNetB0.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469bd300",
   "metadata": {},
   "source": [
    "# LOOK AT EXTRACTING THE MISSCLASSIFIED IMAGES AND TALK ABOUT WHY THEY HAVE BEEN MISSCLASSIFIED (SIMILAR FEATURES, LOOKS LIKE A SUNSET ETC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2996cca1",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3a06007",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 10:18:06.389849: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-26 10:18:06.389867: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-04-26 10:18:09.147688: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 10:18:09.147859: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:18:09.147914: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:18:09.148174: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:18:09.148218: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:18:09.148255: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:18:09.148292: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:18:09.148326: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:18:09.148364: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:18:09.148371: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-04-26 10:18:09.148724: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 381 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import functions\n",
    "\n",
    "data_dir = pathlib.Path('/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/data/Training and Validation')\n",
    "test_dir = pathlib.Path('/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/data/Testing')\n",
    "\n",
    "loaded_model = tf.keras.models.load_model('models/model00_EfficientNetB0.h5')\n",
    "img_height, img_width, batch_size = [224, 224, 32]\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    shuffle = True,\n",
    "    seed = 89787,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'binary'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7efb52e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "figure has been saved to: /home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/plots/CM_NO_IA_1_EfficientNetB0.png\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix, cm = functions.ConfusionMatrix(loaded_model, \n",
    "                                             test_ds, \n",
    "                                             save_fig = True, \n",
    "                                             save_fig_location = \"/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/plots/CM_NO_IA_1_EfficientNetB0.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc554da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions.CreateMetricsReport(model = loaded_model,\n",
    "                             dataset = test_ds,\n",
    "                             confusion_matrix = confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a63ab7",
   "metadata": {},
   "source": [
    "## Testing on custom images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73655c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import os\n",
    "import functions\n",
    "\n",
    "loaded_model = tf.keras.models.load_model('models/model00_EfficientNetB0.h5')\n",
    "input_shape = (224, 224)\n",
    "img_directory = '/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/data/Photos-001/'\n",
    "\n",
    "test_preds = functions.TestImages(img_directory, input_shape, loaded_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e73947",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in test_preds:\n",
    "    if i>0.5:\n",
    "        print(\"no fire\")\n",
    "    else:\n",
    "        count += 1\n",
    "        print(\"fire\")\n",
    "print('Incorrectly predicted ', count,  ' out of ',len(test_preds), '. FPR: ', round(count/len(test_preds), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9672f5e",
   "metadata": {},
   "source": [
    "## Testing on other dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e43a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import functions\n",
    "\n",
    "data_dir = '../../data/Alt_dataset/Training Dataset'\n",
    "loaded_model = tf.keras.models.load_model('models/model00_EfficientNetB0.h5')\n",
    "\n",
    "img_height, img_width, batch_size = [224, 224, 32] \n",
    "\n",
    "\n",
    "data_dir = '../../data/Alt_dataset/Training Dataset'\n",
    "loaded_model = tf.keras.models.load_model('models/model00_EfficientNetB0.h5')\n",
    "\n",
    "img_height, img_width, batch_size = [224, 224, 32] \n",
    "\n",
    "custom_test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    shuffle = True,\n",
    "    seed = 89787,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'binary'\n",
    "    )\n",
    "\n",
    "## Check if images are in the right format\n",
    "\n",
    "bad_file_list = functions.CheckImagesReport(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612806f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Delete the incompatible files from the folder\n",
    "if bad_file_list:\n",
    "    functions.DeleteIncompatibleImages(bad_file_list)\n",
    "else:\n",
    "    print(\"No incompatible files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc93657f",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix, cm = functions.ConfusionMatrix(loaded_model, \n",
    "                                             custom_test_ds, \n",
    "                                             save_fig = True, \n",
    "                                             save_fig_location = \"/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/plots/CM_NO_IA_2_EfficientNetB0.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8f4c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions.CreateMetricsReport(model = loaded_model,\n",
    "                             dataset = custom_test_ds,\n",
    "                             confusion_matrix = confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5953a9a",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9aed12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d7fba4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
