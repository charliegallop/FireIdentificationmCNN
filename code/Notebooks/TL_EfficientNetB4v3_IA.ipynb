{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5275f9d4",
   "metadata": {
    "id": "5275f9d4"
   },
   "source": [
    "# Transfer Learning using EfficientNetB4 - Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7f5404",
   "metadata": {
    "id": "2c7f5404"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "l0gRVGQHHaLM",
   "metadata": {
    "id": "l0gRVGQHHaLM"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c533c7cf",
   "metadata": {
    "id": "c533c7cf"
   },
   "outputs": [],
   "source": [
    "data_dir =pathlib.Path('/content/drive/MyDrive/Colab Notebooks/data/Training and Validation')\n",
    "test_dir =pathlib.Path('/content/drive/MyDrive/Colab Notebooks/data/Testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f486566",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4f486566",
    "outputId": "c27432fb-0f1c-47f5-bcc6-120d063441aa"
   },
   "outputs": [],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d003e205",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "id": "d003e205",
    "outputId": "f9b43eb1-9e99-4f28-d682-a90a3f9995ec"
   },
   "outputs": [],
   "source": [
    "fire = list(data_dir.glob('fire/*'))\n",
    "img = PIL.Image.open(str(fire[0]))\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337fab46",
   "metadata": {
    "id": "337fab46"
   },
   "source": [
    "### Load data into a tf dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5bf1e0",
   "metadata": {
    "id": "5e5bf1e0"
   },
   "source": [
    "Image input size: https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8956881",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b8956881",
    "outputId": "69c9d776-8aa7-40ed-f338-29c2cf7bd641"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "# Validation split 80/20\n",
    "training_gen = ImageDataGenerator(horizontal_flip=True,\n",
    "                                  vertical_flip=True,\n",
    "                                  zoom_range=0.2,\n",
    "                                  width_shift_range=0.2,\n",
    "                                  height_shift_range=0.2,\n",
    "                                  brightness_range = (0.75, 1.25),\n",
    "                                  validation_split=0.2,\n",
    "                                  rotation_range = 30)\n",
    "\n",
    "\n",
    "train_ds = training_gen.flow_from_directory(data_dir, \n",
    "                                            target_size=(img_height, img_width), \n",
    "                                            color_mode = 'rgb',\n",
    "                                            class_mode='binary',\n",
    "                                            batch_size=batch_size,\n",
    "                                            subset='training')\n",
    "\n",
    "val_ds = training_gen.flow_from_directory(data_dir,\n",
    "                                            target_size=(img_height, img_width),\n",
    "                                            color_mode='rgb',\n",
    "                                            class_mode = 'binary',\n",
    "                                            batch_size=batch_size,\n",
    "                                            subset='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73287a5",
   "metadata": {
    "id": "e73287a5"
   },
   "source": [
    "## Seeing what augmentation is applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b0117b",
   "metadata": {
    "id": "78b0117b"
   },
   "outputs": [],
   "source": [
    "from numpy import expand_dims\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69b50af",
   "metadata": {
    "id": "d69b50af"
   },
   "outputs": [],
   "source": [
    "img = load_img(f'{data_dir}/fire/fire_0132.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c63ed8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "id": "24c63ed8",
    "outputId": "069495c7-7b8d-464f-aeb7-da778eab938a"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "data = img_to_array(img)\n",
    "samples = expand_dims(data, 0)\n",
    "it = training_gen.flow(samples, batch_size=1)\n",
    "\n",
    "\n",
    "# generate samples and plot\n",
    "for i in range(3):\n",
    "\t# define subplot\n",
    "\tpyplot.figure(figsize=(25,25))\n",
    "pyplot.subplot(330 + 1+i)\n",
    "\t# generate batch of images\n",
    "batch = it.next()\n",
    "\t# convert to unsigned integers for viewing\n",
    "image = batch[0].astype('uint8')\n",
    "\t# plot raw pixel data\n",
    "pyplot.imshow(image)\n",
    "# show the figure\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203a9337",
   "metadata": {
    "id": "203a9337"
   },
   "source": [
    "### Get Class Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eb59b0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "05eb59b0",
    "outputId": "6b0b3aae-f65c-4fb7-b3de-5040da62519f"
   },
   "outputs": [],
   "source": [
    "class_names = list(train_ds.class_indices.keys())\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eacd4ec",
   "metadata": {
    "id": "6eacd4ec"
   },
   "source": [
    "### Create the base model from pre-trained convnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3848b9bb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3848b9bb",
    "outputId": "b49d95ce-a33d-4e16-9ed6-5c15355c9db3"
   },
   "outputs": [],
   "source": [
    "## By specifying \"include_top=False\" argument you load a network that doesn't include the classification layers at the top, which is ideal for feature extraction\n",
    "IMG_SHAPE = (img_width, img_height) + (3,)\n",
    "base_model = tf.keras.applications.EfficientNetB4(    \n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=IMG_SHAPE,\n",
    "    classifier_activation=\"softmax\")\n",
    "\n",
    "image_batch, label_batch = next(iter(train_ds))\n",
    "feature_batch = base_model(image_batch)\n",
    "print(feature_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d556cb85",
   "metadata": {
    "id": "d556cb85"
   },
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9565031",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c9565031",
    "outputId": "fafb58a2-8661-4159-e87e-a362a9ad4e93"
   },
   "outputs": [],
   "source": [
    "base_model.trainable = False\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a588b0",
   "metadata": {
    "id": "c4a588b0"
   },
   "source": [
    "## Add classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646d6dac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "646d6dac",
    "outputId": "298b5b08-3eb4-442f-dad4-4be5dc3b4008"
   },
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "feature_batch_average = global_average_layer(feature_batch)\n",
    "print(feature_batch_average.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731a52e1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "731a52e1",
    "outputId": "f2741079-c932-4ce5-da19-ca425c5dfefc"
   },
   "outputs": [],
   "source": [
    "prediction_layer = tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "prediction_batch = prediction_layer(feature_batch_average)\n",
    "print(prediction_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c14432",
   "metadata": {
    "id": "64c14432"
   },
   "source": [
    "### Chain together the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434043f0",
   "metadata": {
    "id": "434043f0"
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape = (IMG_SHAPE))\n",
    "x = base_model(inputs, training = False)\n",
    "x = global_average_layer(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38854ac",
   "metadata": {
    "id": "f38854ac"
   },
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf891c5",
   "metadata": {
    "id": "2bf891c5"
   },
   "outputs": [],
   "source": [
    "# Useful metrics paper:\n",
    "# https://www.tensorflow.org/tutorials/structured_data/imbalanced_data\n",
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = base_learning_rate),\n",
    "              loss = tf.keras.losses.BinaryCrossentropy(from_logits=(True)),\n",
    "              metrics = [tf.keras.metrics.Precision(name = \"precision\"),\n",
    "                         tf.keras.metrics.Recall(name = \"recall\"),\n",
    "                         tf.keras.metrics.AUC(name = \"auc\")]\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ecfa6e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c0ecfa6e",
    "outputId": "63a0998a-3a2a-4ea5-e864-6fd9b5d52618"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e69fcf2",
   "metadata": {
    "id": "3e69fcf2"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cb8078",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "75cb8078",
    "outputId": "a48e09d8-148c-4c5c-e21f-d9ac109e5da2"
   },
   "outputs": [],
   "source": [
    "# Tests the initial base model\n",
    "initial_epochs = 10\n",
    "loss0, precision0, recall0, auc0 = model.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23442254",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "23442254",
    "outputId": "ed1117eb-2c98-49f6-dbd7-10ecb9b74dfb"
   },
   "outputs": [],
   "source": [
    "print(\"initial loss: {:.2f}\".format(loss0))\n",
    "print(\"initial precision: {:.2f}\".format(precision0))\n",
    "print(\"initial recall: {:.2f}\".format(recall0))\n",
    "print(\"initial auc: {:.2f}\".format(auc0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddd5b74",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ddd5b74",
    "outputId": "26c7b7d5-f4f2-48ce-9715-31f0469d3725"
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_ds,                    \n",
    "                    epochs = initial_epochs,                    \n",
    "                    validation_data = val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cf5555",
   "metadata": {
    "id": "99cf5555"
   },
   "source": [
    "### Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99220703",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 511
    },
    "id": "99220703",
    "outputId": "e1395f6c-a9c0-4890-c3af-d5f3cd54690e"
   },
   "outputs": [],
   "source": [
    "recall = history.history['recall']\n",
    "val_recall = history.history['val_recall']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "auc = history.history['auc']\n",
    "val_auc = history.history['val_auc']\n",
    "\n",
    "precision = history.history['precision']\n",
    "val_pre = history.history['val_precision']\n",
    "\n",
    "plt.figure(figsize = (16, 16))\n",
    "plt.subplot(4, 2, 1)\n",
    "plt.plot(recall, label = 'Training Recall')\n",
    "plt.plot(val_recall, label='Validation Recall')\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n",
    "                                                              shuffle = True,    \n",
    "                                                              seed = 123,    \n",
    "                                                              image_size = (img_height, img_width),\n",
    "                                                              batch_size = batch_size\n",
    "                                                             )\n",
    "\n",
    "plt.subplot(4, 2, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(4, 2, 3)\n",
    "plt.plot(auc, label = 'Training AUC')\n",
    "plt.plot(val_auc, label='Validation AUC')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('AUC')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation AUC')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(4, 2, 4)\n",
    "plt.plot(precision, label = 'Training Precision')\n",
    "plt.plot(val_pre, label='Validation Precision')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Precision')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f6d61b",
   "metadata": {
    "id": "67f6d61b"
   },
   "source": [
    "## Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc675c0b",
   "metadata": {
    "id": "fc675c0b"
   },
   "outputs": [],
   "source": [
    "# Previously the base model weights were not updated and only a few layers on top of the EfficientNetV2 was trained\n",
    "# Unfreeze and train the top layers of the pre-trained model to fine tune to the dataset\n",
    "\n",
    "## Un-freeze top layers of the model\n",
    "\n",
    "base_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e039116",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1e039116",
    "outputId": "cdc2dfcf-cd51-42e0-e019-965cd21579d7"
   },
   "outputs": [],
   "source": [
    "# Let's take a look to see how many layers are in the base model#\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30f4bea",
   "metadata": {
    "id": "d30f4bea"
   },
   "outputs": [],
   "source": [
    "# Fine-tune from this layer onwards\n",
    "\n",
    "fine_tune_at = 250\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b78e384",
   "metadata": {
    "id": "5b78e384"
   },
   "source": [
    "### Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b60eb68",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1b60eb68",
    "outputId": "43e36bfb-0178-4e1c-eb52-4fb60e3a85e2"
   },
   "outputs": [],
   "source": [
    "## Important to use a lower training weight since using more layers, otherwise\n",
    "# it could overfit very quickly \n",
    "model.compile(loss = tf.keras.losses.BinaryCrossentropy(from_logits = True),\n",
    "              optimizer = tf.keras.optimizers.RMSprop(learning_rate = base_learning_rate/10),\n",
    "              metrics = [tf.keras.metrics.Precision(name = \"precision\"),\n",
    "                         tf.keras.metrics.Recall(name = \"recall\"),\n",
    "                         tf.keras.metrics.AUC(name = \"auc\")])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d543d1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a1d543d1",
    "outputId": "f91b26d0-a7c9-4754-9092-ab97482bb3d0"
   },
   "outputs": [],
   "source": [
    "print(len(model.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238b6d3b",
   "metadata": {
    "id": "238b6d3b"
   },
   "source": [
    "### Continue Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40db2745",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "40db2745",
    "outputId": "2f3522ed-5c36-4b1c-d6c6-f77fde38eaeb"
   },
   "outputs": [],
   "source": [
    "fine_tune_epochs = 10\n",
    "total_epochs = initial_epochs + fine_tune_epochs\n",
    "history_fine = model.fit(train_ds,\n",
    "                         epochs = total_epochs,\n",
    "                         initial_epoch = history.epoch[-1],\n",
    "                         validation_data = val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e306396",
   "metadata": {
    "id": "6e306396"
   },
   "source": [
    "### Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf88e67",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 494
    },
    "id": "2cf88e67",
    "outputId": "5c9fc784-e4f6-4f84-a3c7-50f0aff28e34",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recall += history_fine.history['recall']\n",
    "val_recall += history_fine.history['val_recall']\n",
    "\n",
    "loss += history_fine.history['loss']\n",
    "val_loss += history_fine.history['val_loss']\n",
    "\n",
    "auc += history_fine.history['auc']\n",
    "val_auc += history_fine.history['val_auc']\n",
    "\n",
    "precision += history_fine.history['precision']\n",
    "val_pre += history_fine.history['val_precision']\n",
    "\n",
    "plt.figure(figsize = (16, 16))\n",
    "plt.subplot(4, 2, 1)\n",
    "plt.plot(recall, label = 'Training Recall')\n",
    "plt.plot(val_recall, label='Validation Recall')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(),\n",
    "         label='Start Fine Tuning')\n",
    "plt.title('Training and Validation Recall')\n",
    "plt.subplot(4, 2, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), \n",
    "         label='Start Fine Tuning')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.subplot(4, 2, 3)\n",
    "plt.plot(auc, label = 'Training AUC')\n",
    "plt.plot(val_auc, label='Validation AUC')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('AUC')\n",
    "plt.ylim([0.7,1.0])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), \n",
    "         label='Start Fine Tuning')\n",
    "plt.title('Training and Validation AUC')\n",
    "plt.xlabel('epoch')\n",
    "plt.subplot(4, 2, 4)\n",
    "plt.plot(precision, label = 'Training Precision')\n",
    "plt.plot(val_pre, label='Validation Precision')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.7,1.0])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(),\n",
    "         label='Start Fine Tuning')\n",
    "plt.title('Training and Validation Precision')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e96f150",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5e96f150",
    "outputId": "901e3926-d0f3-4f6a-bd39-c01e4979ba7b"
   },
   "outputs": [],
   "source": [
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n",
    "                                                              shuffle = True,\n",
    "                                                              seed = 123,    \n",
    "                                                              image_size = (img_height, img_width),\n",
    "                                                              batch_size = batch_size    \n",
    "                                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CWsfYQJFkSbf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CWsfYQJFkSbf",
    "outputId": "7bdd2d83-2bd8-42da-cada-7f7e1baf515d"
   },
   "outputs": [],
   "source": [
    "print(model.metrics_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060cebc0",
   "metadata": {
    "id": "060cebc0"
   },
   "source": [
    "## Verifying on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396da123",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "396da123",
    "outputId": "a9362775-821a-48d0-f7f0-be6afb245aca"
   },
   "outputs": [],
   "source": [
    "loss, precision, recall, auc = model.evaluate(test_ds)\n",
    "print('Test loss :', loss)\n",
    "print('Test precision :', precision)\n",
    "print('Test recall :', recall)\n",
    "print('Test auc :', auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74a4318",
   "metadata": {
    "id": "d74a4318"
   },
   "outputs": [],
   "source": [
    "# Retrieve a batch of images from the test set\n",
    "image_batch, label_batch = test_ds.as_numpy_iterator().next()\n",
    "predictions = model.predict_on_batch(image_batch).flatten()\n",
    "# pred = model.predict(test_ds)\n",
    "# pred = np.argmax(pred, axis = 1)[:5]\n",
    "# label = \n",
    "\n",
    "# Apply a sigmoid since our model returns logits\n",
    "#predictions = tf.nn.sigmoid(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955702b8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "955702b8",
    "outputId": "64559f5c-215e-4513-fa28-10b8181630e7"
   },
   "outputs": [],
   "source": [
    "print(np.round(predictions, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41597eda",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "41597eda",
    "outputId": "ab9e50fd-db31-4ec0-9950-423e6a147ecf"
   },
   "outputs": [],
   "source": [
    "predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fc5570",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 626
    },
    "id": "60fc5570",
    "outputId": "720c1451-8178-4a72-a9f8-16b472bdaf0a"
   },
   "outputs": [],
   "source": [
    "# Retrieve a batch of images from the test set\n",
    "image_batch, label_batch = test_ds.as_numpy_iterator().next()\n",
    "predictions = model.predict_on_batch(image_batch).flatten()\n",
    "# pred = model.predict(test_ds)\n",
    "# pred = np.argmax(pred, axis = 1)[:5]\n",
    "# label = \n",
    "\n",
    "# Apply a sigmoid since our model returns logits\n",
    "#predictions = tf.nn.sigmoid(predictions)\n",
    "predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "print('Predictions:', predictions.numpy())\n",
    "print('Labels:', label_batch)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i in range(9):  \n",
    "    ax = plt.subplot(3, 3, i + 1)  \n",
    "    plt.imshow(image_batch[i].astype(\"uint8\"))  \n",
    "    plt.title(class_names[predictions[i]])  \n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d9039f",
   "metadata": {
    "id": "45d9039f"
   },
   "source": [
    "## Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c46f3b",
   "metadata": {
    "id": "94c46f3b"
   },
   "outputs": [],
   "source": [
    "model.save('models/IA_model00_EfficientNetB4.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dda31b",
   "metadata": {
    "id": "13dda31b"
   },
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f30e365c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "f30e365c",
    "outputId": "b51ab6a4-4839-4561-b5de-e019f9f6ef1a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 10:42:18.274627: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-26 10:42:18.274645: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-04-26 10:42:20.254403: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 10:42:20.254578: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:42:20.254621: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:42:20.254654: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:42:20.254685: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:42:20.254715: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:42:20.254745: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:42:20.254775: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:42:20.254805: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-26 10:42:20.254812: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-04-26 10:42:20.255031: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 381 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import functions\n",
    "\n",
    "data_dir = pathlib.Path('/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/data/Training and Validation')\n",
    "test_dir = pathlib.Path('/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/data/Testing')\n",
    "loaded_model = tf.keras.models.load_model('models/IA_model00_EfficientNetB4.h5')\n",
    "\n",
    "img_height, img_width, batch_size = [224, 224, 32]\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n",
    "                                                              shuffle = True,\n",
    "                                                              seed = 89787,\n",
    "                                                              image_size = (img_height, img_width),\n",
    "                                                              batch_size = batch_size,\n",
    "                                                              labels = 'inferred',\n",
    "                                                              label_mode = 'binary'\n",
    "                                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cb52a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "figure has been saved to: /home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/plots/EfficientNetB4/CM_IA_1_EfficientNetB4.svg\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix, cm = functions.ConfusionMatrix(loaded_model, \n",
    "                                             test_ds, \n",
    "                                             save_fig = True, \n",
    "                                             save_fig_location = \"/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/plots/EfficientNetB4/CM_IA_1_EfficientNetB4.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c04d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions.CreateMetricsReport(model = loaded_model,\n",
    "                             dataset = test_ds,\n",
    "                             confusion_matrix = confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe1ad58",
   "metadata": {},
   "source": [
    "## Testing on other dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ede5348d",
   "metadata": {
    "id": "ede5348d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2204 files belonging to 2 classes.\n",
      "processing class directory  NoFire\n",
      "processing class directory  Fire\n",
      " no improper image files were found\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import functions\n",
    "\n",
    "data_dir = '../../data/Alt_dataset/Training Dataset'\n",
    "loaded_model = tf.keras.models.load_model('models/IA_model00_EfficientNetB4.h5')\n",
    "\n",
    "img_height, img_width, batch_size = [224, 224, 32] \n",
    "\n",
    "custom_test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    shuffle = True,\n",
    "    seed = 89787,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'binary'\n",
    "    )\n",
    "\n",
    "## Check if images are in the right format\n",
    "\n",
    "bad_file_list = functions.CheckImagesReport(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9d82d2c",
   "metadata": {
    "id": "f9d82d2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No incompatible files\n"
     ]
    }
   ],
   "source": [
    "## Delete the incompatible files from the folder\n",
    "if bad_file_list:\n",
    "    functions.DeleteIncompatibleImages(bad_file_list)\n",
    "else:\n",
    "    print(\"No incompatible files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e2cb656",
   "metadata": {
    "id": "9e2cb656"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "figure has been saved to: /home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/plots/EfficientNetB4/CM_IA_2_EfficientNetB4.svg\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix, cm = functions.ConfusionMatrix(loaded_model, \n",
    "                                             custom_test_ds, \n",
    "                                             save_fig = True, \n",
    "                                             save_fig_location = \"/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/plots/EfficientNetB4/CM_IA_2_EfficientNetB4.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28a0faf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charlie/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 121s 2s/step - loss: 0.3540 - precision: 0.9643 - recall: 0.8339 - auc: 0.9652\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.96915   0.85372   0.90778      1251\n",
      "           1    0.83394   0.96432   0.89440       953\n",
      "\n",
      "    accuracy                        0.90154      2204\n",
      "   macro avg    0.90154   0.90902   0.90109      2204\n",
      "weighted avg    0.91068   0.90154   0.90199      2204\n",
      "\n",
      "Test loss : 0.35399\n",
      "Test auc : 0.96521\n",
      "Test accuracy:  0.90154\n"
     ]
    }
   ],
   "source": [
    "functions.CreateMetricsReport(model = loaded_model,\n",
    "                             dataset = custom_test_ds,\n",
    "                             confusion_matrix = confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb86061",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "TL_EfficientNetB4v2_IA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
