{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5275f9d4",
   "metadata": {
    "id": "5275f9d4"
   },
   "source": [
    "# Transfer Learning using EfficientNetB4 - Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7f5404",
   "metadata": {
    "id": "2c7f5404"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "l0gRVGQHHaLM",
   "metadata": {
    "id": "l0gRVGQHHaLM"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c533c7cf",
   "metadata": {
    "id": "c533c7cf"
   },
   "outputs": [],
   "source": [
    "data_dir =pathlib.Path('/content/drive/MyDrive/Colab Notebooks/data/Training and Validation')\n",
    "test_dir =pathlib.Path('/content/drive/MyDrive/Colab Notebooks/data/Testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f486566",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4f486566",
    "outputId": "c27432fb-0f1c-47f5-bcc6-120d063441aa"
   },
   "outputs": [],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d003e205",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "id": "d003e205",
    "outputId": "f9b43eb1-9e99-4f28-d682-a90a3f9995ec"
   },
   "outputs": [],
   "source": [
    "fire = list(data_dir.glob('fire/*'))\n",
    "img = PIL.Image.open(str(fire[0]))\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337fab46",
   "metadata": {
    "id": "337fab46"
   },
   "source": [
    "### Load data into a tf dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5bf1e0",
   "metadata": {
    "id": "5e5bf1e0"
   },
   "source": [
    "Image input size: https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8956881",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b8956881",
    "outputId": "69c9d776-8aa7-40ed-f338-29c2cf7bd641"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "# Validation split 80/20\n",
    "training_gen = ImageDataGenerator(horizontal_flip=True,\n",
    "                                  vertical_flip=True,\n",
    "                                  zoom_range=0.2,\n",
    "                                  width_shift_range=0.2,\n",
    "                                  height_shift_range=0.2,\n",
    "                                  brightness_range = (0.75, 1.25),\n",
    "                                  validation_split=0.2,\n",
    "                                  rotation_range = 30)\n",
    "\n",
    "\n",
    "train_ds = training_gen.flow_from_directory(data_dir, \n",
    "                                            target_size=(img_height, img_width), \n",
    "                                            color_mode = 'rgb',\n",
    "                                            class_mode='binary',\n",
    "                                            batch_size=batch_size,\n",
    "                                            subset='training')\n",
    "\n",
    "val_ds = training_gen.flow_from_directory(data_dir,\n",
    "                                            target_size=(img_height, img_width),\n",
    "                                            color_mode='rgb',\n",
    "                                            class_mode = 'binary',\n",
    "                                            batch_size=batch_size,\n",
    "                                            subset='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73287a5",
   "metadata": {
    "id": "e73287a5"
   },
   "source": [
    "## Seeing what augmentation is applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b0117b",
   "metadata": {
    "id": "78b0117b"
   },
   "outputs": [],
   "source": [
    "from numpy import expand_dims\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69b50af",
   "metadata": {
    "id": "d69b50af"
   },
   "outputs": [],
   "source": [
    "img = load_img(f'{data_dir}/fire/fire_0132.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c63ed8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "id": "24c63ed8",
    "outputId": "069495c7-7b8d-464f-aeb7-da778eab938a"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "data = img_to_array(img)\n",
    "samples = expand_dims(data, 0)\n",
    "it = training_gen.flow(samples, batch_size=1)\n",
    "\n",
    "\n",
    "# generate samples and plot\n",
    "for i in range(3):\n",
    "\t# define subplot\n",
    "\tpyplot.figure(figsize=(25,25))\n",
    "pyplot.subplot(330 + 1+i)\n",
    "\t# generate batch of images\n",
    "batch = it.next()\n",
    "\t# convert to unsigned integers for viewing\n",
    "image = batch[0].astype('uint8')\n",
    "\t# plot raw pixel data\n",
    "pyplot.imshow(image)\n",
    "# show the figure\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203a9337",
   "metadata": {
    "id": "203a9337"
   },
   "source": [
    "### Get Class Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eb59b0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "05eb59b0",
    "outputId": "6b0b3aae-f65c-4fb7-b3de-5040da62519f"
   },
   "outputs": [],
   "source": [
    "class_names = list(train_ds.class_indices.keys())\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eacd4ec",
   "metadata": {
    "id": "6eacd4ec"
   },
   "source": [
    "### Create the base model from pre-trained convnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3848b9bb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3848b9bb",
    "outputId": "b49d95ce-a33d-4e16-9ed6-5c15355c9db3"
   },
   "outputs": [],
   "source": [
    "## By specifying \"include_top=False\" argument you load a network that doesn't include the classification layers at the top, which is ideal for feature extraction\n",
    "IMG_SHAPE = (img_width, img_height) + (3,)\n",
    "base_model = tf.keras.applications.EfficientNetB4(    \n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=IMG_SHAPE,\n",
    "    classifier_activation=\"softmax\")\n",
    "\n",
    "image_batch, label_batch = next(iter(train_ds))\n",
    "feature_batch = base_model(image_batch)\n",
    "print(feature_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d556cb85",
   "metadata": {
    "id": "d556cb85"
   },
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9565031",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c9565031",
    "outputId": "fafb58a2-8661-4159-e87e-a362a9ad4e93"
   },
   "outputs": [],
   "source": [
    "base_model.trainable = False\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a588b0",
   "metadata": {
    "id": "c4a588b0"
   },
   "source": [
    "## Add classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646d6dac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "646d6dac",
    "outputId": "298b5b08-3eb4-442f-dad4-4be5dc3b4008"
   },
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "feature_batch_average = global_average_layer(feature_batch)\n",
    "print(feature_batch_average.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731a52e1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "731a52e1",
    "outputId": "f2741079-c932-4ce5-da19-ca425c5dfefc"
   },
   "outputs": [],
   "source": [
    "prediction_layer = tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "prediction_batch = prediction_layer(feature_batch_average)\n",
    "print(prediction_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c14432",
   "metadata": {
    "id": "64c14432"
   },
   "source": [
    "### Chain together the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434043f0",
   "metadata": {
    "id": "434043f0"
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape = (IMG_SHAPE))\n",
    "x = base_model(inputs, training = False)\n",
    "x = global_average_layer(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38854ac",
   "metadata": {
    "id": "f38854ac"
   },
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf891c5",
   "metadata": {
    "id": "2bf891c5"
   },
   "outputs": [],
   "source": [
    "# Useful metrics paper:\n",
    "# https://www.tensorflow.org/tutorials/structured_data/imbalanced_data\n",
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = base_learning_rate),\n",
    "              loss = tf.keras.losses.BinaryCrossentropy(from_logits=(True)),\n",
    "              metrics = [tf.keras.metrics.Precision(name = \"precision\"),\n",
    "                         tf.keras.metrics.Recall(name = \"recall\"),\n",
    "                         tf.keras.metrics.AUC(name = \"auc\")]\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ecfa6e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c0ecfa6e",
    "outputId": "63a0998a-3a2a-4ea5-e864-6fd9b5d52618"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e69fcf2",
   "metadata": {
    "id": "3e69fcf2"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cb8078",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "75cb8078",
    "outputId": "a48e09d8-148c-4c5c-e21f-d9ac109e5da2"
   },
   "outputs": [],
   "source": [
    "# Tests the initial base model\n",
    "initial_epochs = 10\n",
    "loss0, precision0, recall0, auc0 = model.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23442254",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "23442254",
    "outputId": "ed1117eb-2c98-49f6-dbd7-10ecb9b74dfb"
   },
   "outputs": [],
   "source": [
    "print(\"initial loss: {:.2f}\".format(loss0))\n",
    "print(\"initial precision: {:.2f}\".format(precision0))\n",
    "print(\"initial recall: {:.2f}\".format(recall0))\n",
    "print(\"initial auc: {:.2f}\".format(auc0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddd5b74",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ddd5b74",
    "outputId": "26c7b7d5-f4f2-48ce-9715-31f0469d3725"
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_ds,                    \n",
    "                    epochs = initial_epochs,                    \n",
    "                    validation_data = val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cf5555",
   "metadata": {
    "id": "99cf5555"
   },
   "source": [
    "### Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99220703",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 511
    },
    "id": "99220703",
    "outputId": "e1395f6c-a9c0-4890-c3af-d5f3cd54690e"
   },
   "outputs": [],
   "source": [
    "recall = history.history['recall']\n",
    "val_recall = history.history['val_recall']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "auc = history.history['auc']\n",
    "val_auc = history.history['val_auc']\n",
    "\n",
    "precision = history.history['precision']\n",
    "val_pre = history.history['val_precision']\n",
    "\n",
    "plt.figure(figsize = (16, 16))\n",
    "plt.subplot(4, 2, 1)\n",
    "plt.plot(recall, label = 'Training Recall')\n",
    "plt.plot(val_recall, label='Validation Recall')\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n",
    "                                                              shuffle = True,    \n",
    "                                                              seed = 123,    \n",
    "                                                              image_size = (img_height, img_width),\n",
    "                                                              batch_size = batch_size\n",
    "                                                             )\n",
    "\n",
    "plt.subplot(4, 2, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(4, 2, 3)\n",
    "plt.plot(auc, label = 'Training AUC')\n",
    "plt.plot(val_auc, label='Validation AUC')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('AUC')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation AUC')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(4, 2, 4)\n",
    "plt.plot(precision, label = 'Training Precision')\n",
    "plt.plot(val_pre, label='Validation Precision')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Precision')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f6d61b",
   "metadata": {
    "id": "67f6d61b"
   },
   "source": [
    "## Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc675c0b",
   "metadata": {
    "id": "fc675c0b"
   },
   "outputs": [],
   "source": [
    "# Previously the base model weights were not updated and only a few layers on top of the EfficientNetV2 was trained\n",
    "# Unfreeze and train the top layers of the pre-trained model to fine tune to the dataset\n",
    "\n",
    "## Un-freeze top layers of the model\n",
    "\n",
    "base_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e039116",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1e039116",
    "outputId": "cdc2dfcf-cd51-42e0-e019-965cd21579d7"
   },
   "outputs": [],
   "source": [
    "# Let's take a look to see how many layers are in the base model#\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30f4bea",
   "metadata": {
    "id": "d30f4bea"
   },
   "outputs": [],
   "source": [
    "# Fine-tune from this layer onwards\n",
    "\n",
    "fine_tune_at = 250\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b78e384",
   "metadata": {
    "id": "5b78e384"
   },
   "source": [
    "### Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b60eb68",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1b60eb68",
    "outputId": "43e36bfb-0178-4e1c-eb52-4fb60e3a85e2"
   },
   "outputs": [],
   "source": [
    "## Important to use a lower training weight since using more layers, otherwise\n",
    "# it could overfit very quickly \n",
    "model.compile(loss = tf.keras.losses.BinaryCrossentropy(from_logits = True),\n",
    "              optimizer = tf.keras.optimizers.RMSprop(learning_rate = base_learning_rate/10),\n",
    "              metrics = [tf.keras.metrics.Precision(name = \"precision\"),\n",
    "                         tf.keras.metrics.Recall(name = \"recall\"),\n",
    "                         tf.keras.metrics.AUC(name = \"auc\")])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d543d1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a1d543d1",
    "outputId": "f91b26d0-a7c9-4754-9092-ab97482bb3d0"
   },
   "outputs": [],
   "source": [
    "print(len(model.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238b6d3b",
   "metadata": {
    "id": "238b6d3b"
   },
   "source": [
    "### Continue Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40db2745",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "40db2745",
    "outputId": "2f3522ed-5c36-4b1c-d6c6-f77fde38eaeb"
   },
   "outputs": [],
   "source": [
    "fine_tune_epochs = 10\n",
    "total_epochs = initial_epochs + fine_tune_epochs\n",
    "history_fine = model.fit(train_ds,\n",
    "                         epochs = total_epochs,\n",
    "                         initial_epoch = history.epoch[-1],\n",
    "                         validation_data = val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e306396",
   "metadata": {
    "id": "6e306396"
   },
   "source": [
    "### Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf88e67",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 494
    },
    "id": "2cf88e67",
    "outputId": "5c9fc784-e4f6-4f84-a3c7-50f0aff28e34",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recall += history_fine.history['recall']\n",
    "val_recall += history_fine.history['val_recall']\n",
    "\n",
    "loss += history_fine.history['loss']\n",
    "val_loss += history_fine.history['val_loss']\n",
    "\n",
    "auc += history_fine.history['auc']\n",
    "val_auc += history_fine.history['val_auc']\n",
    "\n",
    "precision += history_fine.history['precision']\n",
    "val_pre += history_fine.history['val_precision']\n",
    "\n",
    "plt.figure(figsize = (16, 16))\n",
    "plt.subplot(4, 2, 1)\n",
    "plt.plot(recall, label = 'Training Recall')\n",
    "plt.plot(val_recall, label='Validation Recall')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(),\n",
    "         label='Start Fine Tuning')\n",
    "plt.title('Training and Validation Recall')\n",
    "plt.subplot(4, 2, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), \n",
    "         label='Start Fine Tuning')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.subplot(4, 2, 3)\n",
    "plt.plot(auc, label = 'Training AUC')\n",
    "plt.plot(val_auc, label='Validation AUC')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('AUC')\n",
    "plt.ylim([0.7,1.0])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), \n",
    "         label='Start Fine Tuning')\n",
    "plt.title('Training and Validation AUC')\n",
    "plt.xlabel('epoch')\n",
    "plt.subplot(4, 2, 4)\n",
    "plt.plot(precision, label = 'Training Precision')\n",
    "plt.plot(val_pre, label='Validation Precision')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.7,1.0])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(),\n",
    "         label='Start Fine Tuning')\n",
    "plt.title('Training and Validation Precision')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e96f150",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5e96f150",
    "outputId": "901e3926-d0f3-4f6a-bd39-c01e4979ba7b"
   },
   "outputs": [],
   "source": [
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n",
    "                                                              shuffle = True,\n",
    "                                                              seed = 123,    \n",
    "                                                              image_size = (img_height, img_width),\n",
    "                                                              batch_size = batch_size    \n",
    "                                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CWsfYQJFkSbf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CWsfYQJFkSbf",
    "outputId": "7bdd2d83-2bd8-42da-cada-7f7e1baf515d"
   },
   "outputs": [],
   "source": [
    "print(model.metrics_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060cebc0",
   "metadata": {
    "id": "060cebc0"
   },
   "source": [
    "## Verifying on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396da123",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "396da123",
    "outputId": "a9362775-821a-48d0-f7f0-be6afb245aca"
   },
   "outputs": [],
   "source": [
    "loss, precision, recall, auc = model.evaluate(test_ds)\n",
    "print('Test loss :', loss)\n",
    "print('Test precision :', precision)\n",
    "print('Test recall :', recall)\n",
    "print('Test auc :', auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74a4318",
   "metadata": {
    "id": "d74a4318"
   },
   "outputs": [],
   "source": [
    "# Retrieve a batch of images from the test set\n",
    "image_batch, label_batch = test_ds.as_numpy_iterator().next()\n",
    "predictions = model.predict_on_batch(image_batch).flatten()\n",
    "# pred = model.predict(test_ds)\n",
    "# pred = np.argmax(pred, axis = 1)[:5]\n",
    "# label = \n",
    "\n",
    "# Apply a sigmoid since our model returns logits\n",
    "#predictions = tf.nn.sigmoid(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955702b8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "955702b8",
    "outputId": "64559f5c-215e-4513-fa28-10b8181630e7"
   },
   "outputs": [],
   "source": [
    "print(np.round(predictions, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41597eda",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "41597eda",
    "outputId": "ab9e50fd-db31-4ec0-9950-423e6a147ecf"
   },
   "outputs": [],
   "source": [
    "predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fc5570",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 626
    },
    "id": "60fc5570",
    "outputId": "720c1451-8178-4a72-a9f8-16b472bdaf0a"
   },
   "outputs": [],
   "source": [
    "# Retrieve a batch of images from the test set\n",
    "image_batch, label_batch = test_ds.as_numpy_iterator().next()\n",
    "predictions = model.predict_on_batch(image_batch).flatten()\n",
    "# pred = model.predict(test_ds)\n",
    "# pred = np.argmax(pred, axis = 1)[:5]\n",
    "# label = \n",
    "\n",
    "# Apply a sigmoid since our model returns logits\n",
    "#predictions = tf.nn.sigmoid(predictions)\n",
    "predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "print('Predictions:', predictions.numpy())\n",
    "print('Labels:', label_batch)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i in range(9):  \n",
    "    ax = plt.subplot(3, 3, i + 1)  \n",
    "    plt.imshow(image_batch[i].astype(\"uint8\"))  \n",
    "    plt.title(class_names[predictions[i]])  \n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d9039f",
   "metadata": {
    "id": "45d9039f"
   },
   "source": [
    "## Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c46f3b",
   "metadata": {
    "id": "94c46f3b"
   },
   "outputs": [],
   "source": [
    "model.save('models/IA_model00_EfficientNetB4.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dda31b",
   "metadata": {
    "id": "13dda31b"
   },
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f30e365c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "f30e365c",
    "outputId": "b51ab6a4-4839-4561-b5de-e019f9f6ef1a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-27 15:31:02.987707: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-27 15:31:02.987726: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-04-27 15:31:05.508577: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-27 15:31:05.508744: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-27 15:31:05.508943: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-27 15:31:05.509085: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-27 15:31:05.509219: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-27 15:31:05.509351: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-27 15:31:05.509498: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-27 15:31:05.509537: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-27 15:31:05.509573: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-27 15:31:05.509581: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-04-27 15:31:05.509808: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 381 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import functions\n",
    "\n",
    "data_dir = pathlib.Path('/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/data/Training and Validation')\n",
    "test_dir = pathlib.Path('/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/data/Testing')\n",
    "loaded_model = tf.keras.models.load_model('models/IA_model00_EfficientNetB4.h5')\n",
    "\n",
    "img_height, img_width, batch_size = [224, 224, 32]\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n",
    "                                                              shuffle = True,\n",
    "                                                              seed = 89787,\n",
    "                                                              image_size = (img_height, img_width),\n",
    "                                                              batch_size = batch_size,\n",
    "                                                              labels = 'inferred',\n",
    "                                                              label_mode = 'binary'\n",
    "                                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cb52a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[189   5]\n",
      " [  1 186]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "figure has been saved to: /home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/plots/EfficientNetB4/CM_IA_1_EfficientNetB4.svg\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix, cm = functions.ConfusionMatrix(loaded_model, \n",
    "                                             test_ds, \n",
    "                                             save_fig = True, \n",
    "                                             save_fig_location = \"/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/plots/EfficientNetB4/CM_IA_1_EfficientNetB4.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c04d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions.CreateMetricsReport(model = loaded_model,\n",
    "                             dataset = test_ds,\n",
    "                             confusion_matrix = confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe1ad58",
   "metadata": {},
   "source": [
    "## Testing on other dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ede5348d",
   "metadata": {
    "id": "ede5348d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2204 files belonging to 2 classes.\n",
      "processing class directory  NoFire\n",
      "processing class directory  Fire\n",
      " no improper image files were found\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import functions\n",
    "\n",
    "data_dir = '../../data/Alt_dataset/Training Dataset'\n",
    "loaded_model = tf.keras.models.load_model('models/IA_model00_EfficientNetB4.h5')\n",
    "\n",
    "img_height, img_width, batch_size = [224, 224, 32] \n",
    "\n",
    "custom_test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    shuffle = True,\n",
    "    seed = 89787,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'binary'\n",
    "    )\n",
    "\n",
    "## Check if images are in the right format\n",
    "\n",
    "bad_file_list = functions.CheckImagesReport(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9d82d2c",
   "metadata": {
    "id": "f9d82d2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No incompatible files\n"
     ]
    }
   ],
   "source": [
    "## Delete the incompatible files from the folder\n",
    "if bad_file_list:\n",
    "    functions.DeleteIncompatibleImages(bad_file_list)\n",
    "else:\n",
    "    print(\"No incompatible files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2cb656",
   "metadata": {
    "id": "9e2cb656"
   },
   "outputs": [],
   "source": [
    "confusion_matrix, cm = functions.ConfusionMatrix(loaded_model, \n",
    "                                             custom_test_ds, \n",
    "                                             save_fig = True, \n",
    "                                             save_fig_location = \"/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/plots/EfficientNetB4/CM_IA_2_EfficientNetB4.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a0faf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions.CreateMetricsReport(model = loaded_model,\n",
    "                             dataset = custom_test_ds,\n",
    "                             confusion_matrix = confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb86061",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "TL_EfficientNetB4v2_IA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
