{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "577a39f9",
   "metadata": {},
   "source": [
    "# Transfer Learning using MobileNetV3_Small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7f5404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c533c7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir =pathlib.Path('/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/data/Training and Validation')\n",
    "test_dir =pathlib.Path('/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/data/Testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f486566",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d003e205",
   "metadata": {},
   "outputs": [],
   "source": [
    "fire = list(data_dir.glob('fire/*'))\n",
    "img = PIL.Image.open(str(fire[0]))\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337fab46",
   "metadata": {},
   "source": [
    "### Load data into a tf dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a9ef1c",
   "metadata": {},
   "source": [
    "Image input sizes: https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8956881",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    "# Validation split 80/20\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split = 0.2,\n",
    "    subset = \"training\",\n",
    "    shuffle = True,\n",
    "    seed = 123,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf95709",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split = 0.2,\n",
    "    subset = \"validation\",\n",
    "    shuffle = True,\n",
    "    seed = 123,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size    \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eeac62",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    shuffle = True,\n",
    "    seed = 123,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203a9337",
   "metadata": {},
   "source": [
    "### Get Class Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eb59b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2982e2fd",
   "metadata": {},
   "source": [
    "### Visualise Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8406f3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89d6dac",
   "metadata": {},
   "source": [
    "### Configure the dataset for performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73585ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.prefetch(buffer_size = AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(buffer_size = AUTOTUNE)\n",
    "test_ds = test_ds.prefetch(buffer_size = AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eacd4ec",
   "metadata": {},
   "source": [
    "### Create the base model from pre-trained convnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3848b9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## By specifying \"include_top=False\" argument you load a network that doesn't \n",
    "## include the classification layers at the top, which is ideal for feature extraction\n",
    "\n",
    "IMG_SHAPE = (img_width, img_height) + (3,)\n",
    "\n",
    "base_model = tf.keras.applications.MobileNetV3Small(\n",
    "    input_shape=IMG_SHAPE,\n",
    "    alpha=1.0,\n",
    "    minimalistic=False,\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_tensor=None,\n",
    "    pooling=None,\n",
    "    dropout_rate=0.2,\n",
    "    classifier_activation='softmax',\n",
    "    include_preprocessing=True\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "image_batch, label_batch = next(iter(train_ds))\n",
    "feature_batch = base_model(image_batch)\n",
    "print(feature_batch.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d556cb85",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9565031",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a588b0",
   "metadata": {},
   "source": [
    "## Add classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646d6dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "feature_batch_average = global_average_layer(feature_batch)\n",
    "print(feature_batch_average.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731a52e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_layer = tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "prediction_batch = prediction_layer(feature_batch_average)\n",
    "print(prediction_batch.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c14432",
   "metadata": {},
   "source": [
    "### Chain together the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434043f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape = (IMG_SHAPE))\n",
    "x = base_model(inputs, training = False)\n",
    "x = global_average_layer(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38854ac",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf891c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful metrics paper:\n",
    "# https://www.tensorflow.org/tutorials/structured_data/imbalanced_data\n",
    "\n",
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = base_learning_rate),\n",
    "              loss = tf.keras.losses.BinaryCrossentropy(from_logits=(True)),\n",
    "              metrics = [tf.keras.metrics.Precision(name = \"precision\"), tf.keras.metrics.Recall(name = \"recall\"),tf.keras.metrics.AUC(name = \"auc\")] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ecfa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e69fcf2",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cb8078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests the initial base model\n",
    "initial_epochs = 10\n",
    "loss0, precision0, recall0, auc0 = model.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23442254",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"initial loss: {:.2f}\".format(loss0))\n",
    "print(\"initial precision: {:.2f}\".format(precision0))\n",
    "print(\"initial recall: {:.2f}\".format(recall0))\n",
    "print(\"initial auc: {:.2f}\".format(auc0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddd5b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds,\n",
    "                    epochs = initial_epochs,\n",
    "                    validation_data = val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cf5555",
   "metadata": {},
   "source": [
    "### Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99220703",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = history.history['recall']\n",
    "val_recall = history.history['val_recall']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "auc = history.history['auc']\n",
    "val_auc = history.history['val_auc']\n",
    "\n",
    "precision = history.history['precision']\n",
    "val_pre = history.history['val_precision']\n",
    "\n",
    "plt.figure(figsize = (16, 16))\n",
    "plt.subplot(4, 2, 1)\n",
    "plt.plot(recall, label = 'Training Recall')\n",
    "plt.plot(val_recall, label='Validation Recall')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    shuffle = True,\n",
    "    seed = 123,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    "    )\n",
    "\n",
    "plt.subplot(4, 2, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(4, 2, 3)\n",
    "plt.plot(auc, label = 'Training AUC')\n",
    "plt.plot(val_auc, label='Validation AUC')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('AUC')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation AUC')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(4, 2, 4)\n",
    "plt.plot(precision, label = 'Training Precision')\n",
    "plt.plot(val_pre, label='Validation Precision')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Precision')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f6d61b",
   "metadata": {},
   "source": [
    "## Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc675c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previously the base model weights were not updated and only a few layers on top of the EfficientNetV2 was trained\n",
    "# Unfreeze and train the top layers of the pre-trained model to fine tune to the dataset\n",
    "\n",
    "## Un-freeze top layers of the model\n",
    "\n",
    "base_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e039116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look to see how many layers are in the base model\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30f4bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 100\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b78e384",
   "metadata": {},
   "source": [
    "### Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b60eb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Important to use a lower training weight since using more layers, otherwise\n",
    "# it could overfit very quickly \n",
    "\n",
    "model.compile(loss = tf.keras.losses.BinaryCrossentropy(from_logits = True),\n",
    "              optimizer = tf.keras.optimizers.RMSprop(learning_rate = base_learning_rate/10),\n",
    "              metrics = [tf.keras.metrics.Precision(name = \"precision\"), tf.keras.metrics.Recall(name = \"recall\"),tf.keras.metrics.AUC(name = \"auc\")])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d543d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(model.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238b6d3b",
   "metadata": {},
   "source": [
    "### Continue Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40db2745",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_epochs = 10\n",
    "total_epochs = initial_epochs + fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(train_ds,\n",
    "                         epochs = total_epochs,\n",
    "                         initial_epoch = history.epoch[-1],\n",
    "                         validation_data = val_ds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e306396",
   "metadata": {},
   "source": [
    "### Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf88e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall += history_fine.history['recall']\n",
    "val_recall += history_fine.history['val_recall']\n",
    "\n",
    "loss += history_fine.history['loss']\n",
    "val_loss += history_fine.history['val_loss']\n",
    "\n",
    "auc += history_fine.history['auc']\n",
    "val_auc += history_fine.history['val_auc']\n",
    "\n",
    "precision += history_fine.history['precision']\n",
    "val_pre += history_fine.history['val_precision']\n",
    "\n",
    "plt.figure(figsize = (16, 16))\n",
    "plt.subplot(4, 2, 1)\n",
    "plt.plot(recall, label = 'Training Recall')\n",
    "plt.plot(val_recall, label='Validation Recall')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.title('Training and Validation Recall')\n",
    "\n",
    "plt.subplot(4, 2, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(4, 2, 3)\n",
    "plt.plot(auc, label = 'Training AUC')\n",
    "plt.plot(val_auc, label='Validation AUC')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('AUC')\n",
    "plt.ylim([0.7,1.0])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.title('Training and Validation AUC')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(4, 2, 4)\n",
    "plt.plot(precision, label = 'Training Precision')\n",
    "plt.plot(val_pre, label='Validation Precision')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.7,1.0])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.title('Training and Validation Precision')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e96f150",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    shuffle = True,\n",
    "    seed = 123,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size\n",
    "    )\n",
    "\n",
    "\n",
    "test_ds = test_ds.prefetch(buffer_size = AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060cebc0",
   "metadata": {},
   "source": [
    "## Verifying on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396da123",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, precision, recall, auc = model.evaluate(test_ds)\n",
    "print('Test loss :', loss)\n",
    "print('Test precision :', precision)\n",
    "print('Test recall :', recall)\n",
    "print('Test auc :', auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74a4318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve a batch of images from the test set\n",
    "image_batch, label_batch = test_ds.as_numpy_iterator().next()\n",
    "predictions = model.predict_on_batch(image_batch).flatten()\n",
    "\n",
    "# pred = model.predict(test_ds)\n",
    "# pred = np.argmax(pred, axis = 1)[:5]\n",
    "# label = \n",
    "\n",
    "# Apply a sigmoid since our model returns logits\n",
    "#predictions = tf.nn.sigmoid(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955702b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.round(predictions, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41597eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fc5570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve a batch of images from the test set\n",
    "image_batch, label_batch = test_ds.as_numpy_iterator().next()\n",
    "predictions = model.predict_on_batch(image_batch).flatten()\n",
    "\n",
    "# pred = model.predict(test_ds)\n",
    "# pred = np.argmax(pred, axis = 1)[:5]\n",
    "# label = \n",
    "\n",
    "# Apply a sigmoid since our model returns logits\n",
    "#predictions = tf.nn.sigmoid(predictions)\n",
    "predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "\n",
    "print('Predictions:\\n', predictions.numpy())\n",
    "print('Labels:\\n', label_batch)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "  ax = plt.subplot(3, 3, i + 1)\n",
    "  plt.imshow(image_batch[i].astype(\"uint8\"))\n",
    "  plt.title(class_names[predictions[i]])\n",
    "  plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffc499e",
   "metadata": {},
   "source": [
    "## Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9615b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model00_MobileNetv3_Small.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469bd300",
   "metadata": {},
   "source": [
    "# LOOK AT EXTRACTING THE MISSCLASSIFIED IMAGES AND TALK ABOUT WHY THEY HAVE BEEN MISSCLASSIFIED (SIMILAR FEATURES, LOOKS LIKE A SUNSET ETC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2996cca1",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1305b06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-13 14:04:33.402136: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-13 14:04:33.402158: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-04-13 14:04:36.033447: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-13 14:04:36.033710: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-13 14:04:36.033758: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-13 14:04:36.033795: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-13 14:04:36.033834: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-13 14:04:36.033873: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-13 14:04:36.033911: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-13 14:04:36.033948: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-13 14:04:36.033985: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/charlie/miniconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-13 14:04:36.033993: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-04-13 14:04:36.034290: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 381 files belonging to 2 classes.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import functions\n",
    "data_dir = pathlib.Path('/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/data/Training and Validation')\n",
    "test_dir = pathlib.Path('/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/data/Testing')\n",
    "\n",
    "loaded_model = tf.keras.models.load_model('models/model00_MobileNetv3_Small.h5')\n",
    "img_height, img_width, batch_size = [224, 224, 32]\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    shuffle = True,\n",
    "    seed = 89787,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'binary'\n",
    "    )\n",
    "\n",
    "functions.ConfusionMatrix(loaded_model, test_ds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f2e891",
   "metadata": {},
   "source": [
    "## Testing on custom images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c087bfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import os\n",
    "import functions\n",
    "\n",
    "loaded_model = tf.keras.models.load_model('models/model00_MobileNetv3_Small.h5')\n",
    "input_shape = (224, 224)\n",
    "img_directory = '/home/charlie/Documents/Uni/Exeter - Data Science/MTHM602_Trends_in_data_science_and_AI/Project/data/Photos-001/'\n",
    "\n",
    "test_preds = functions.TestImages(img_directory, input_shape, loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2c4eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in test_preds:\n",
    "    if i>0.5:\n",
    "        print(\"no fire\")\n",
    "    else:\n",
    "        count += 1\n",
    "        print(\"fire\")\n",
    "print('Incorrectly predicted ', count,  ' out of ',len(test_preds), '. FPR: ', round(count/len(test_preds), 2))"
<<<<<<< HEAD
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc8bcca",
   "metadata": {},
   "source": [
    "## Testing on other dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a93d3b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2367 files belonging to 2 classes.\n",
      "processing class directory  NoFire\n",
      "processing class directory  Fire\n",
      " no improper image files were found\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import functions\n",
    "\n",
    "data_dir = '../../data/Alt_dataset/Training Dataset'\n",
    "loaded_model = tf.keras.models.load_model('models/model00_MobileNetv3_Small.h5')\n",
    "\n",
    "img_height, img_width, batch_size = [224, 224, 32] \n",
    "\n",
    "custom_test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    shuffle = True,\n",
    "    seed = 89787,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'binary'\n",
    "    )\n",
    "\n",
    "## Check if images are in the right format\n",
    "\n",
    "bad_file_list = functions.CheckImagesReport(data_dir)"
=======
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc8bcca",
   "metadata": {},
   "source": [
    "## Testing on other dataset"
>>>>>>> 28f2b404cfbf3010b5fa1206a34e87f728822052
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
   "id": "641d8886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No incompatible files\n"
     ]
    }
   ],
   "source": [
    "## Delete the incompatible files from the folder\n",
    "if bad_file_list:\n",
    "    functions.DeleteIncompatibleImages(bad_file_list)\n",
    "else:\n",
    "    print(\"No incompatible files\")\n"
=======
   "execution_count": null,
   "id": "a93d3b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import functions\n",
    "\n",
    "data_dir = '../../data/Alt_dataset/Training Dataset'\n",
    "loaded_model = tf.keras.models.load_model('models/model00_MobileNetv3_Small.h5')\n",
    "\n",
    "img_height, img_width, batch_size = [224, 224, 32] \n",
    "\n",
    "custom_test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    shuffle = True,\n",
    "    seed = 89787,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'binary'\n",
    "    )\n",
    "\n",
    "## Check if images are in the right format\n",
    "\n",
    "bad_file_list = functions.CheckImagesReport(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641d8886",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Delete the incompatible files from the folder\n",
    "functions.DeleteIncompatibleImages(bad_file_list)\n"
>>>>>>> 28f2b404cfbf3010b5fa1206a34e87f728822052
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
   "id": "ce001a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
=======
   "execution_count": null,
   "id": "ce001a79",
   "metadata": {},
   "outputs": [],
>>>>>>> 28f2b404cfbf3010b5fa1206a34e87f728822052
   "source": [
    "functions.ConfusionMatrix(loaded_model, custom_test_ds)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
   "id": "18fa0a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charlie/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 12s 147ms/step - loss: 0.4386 - precision: 0.9286 - recall: 0.8435 - auc: 0.9454\n",
      "Test loss : 0.43857541680336\n",
      "Test precision : 0.9286335706710815\n",
      "Test recall : 0.843478262424469\n",
      "Test auc : 0.9454187154769897\n"
     ]
    }
   ],
=======
   "execution_count": null,
   "id": "18fa0a83",
   "metadata": {},
   "outputs": [],
>>>>>>> 28f2b404cfbf3010b5fa1206a34e87f728822052
   "source": [
    "loss, precision, recall, auc = loaded_model.evaluate(custom_test_ds)\n",
    "print('Test loss :', loss)\n",
    "print('Test precision :', precision)\n",
    "print('Test recall :', recall)\n",
    "print('Test auc :', auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbb828d",
   "metadata": {},
   "source": [
    "# Feature map extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a019080d",
   "metadata": {},
   "source": [
    "from: https://towardsdatascience.com/convolutional-neural-network-feature-map-and-filter-visualization-f75012a5a49c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c75d1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = f'{test_dir}/nofire/abc191.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da11f676",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate thru all the layers of the model\n",
    "for layer in base_model.layers:\n",
    "    if 'conv' in layer.name:\n",
    "        weights = layer.get_weights()\n",
    "        print(weights)\n",
    "        \n",
    "        #normalize filter values between  0 and 1 for visualization\n",
    "        f_min, f_max = weights.min(), weights.max()\n",
    "        filters = (weights - f_min) / (f_max - f_min)  \n",
    "        print(filters.shape[3])\n",
    "        filter_cnt=1\n",
    "        \n",
    "        #plotting all the filters\n",
    "        for i in range(filters.shape[3]):\n",
    "            #get the filters\n",
    "            filt=filters[:,:,:, i]\n",
    "            #plotting each of the channel, color image RGB channels\n",
    "            for j in range(filters.shape[0]):\n",
    "                ax= plt.subplot(filters.shape[3], filters.shape[0], filter_cnt  )\n",
    "                ax.set_xticks([])\n",
    "                ax.set_yticks([])\n",
    "                plt.imshow(filt[:,:, j])\n",
    "                filter_cnt+=1\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82af638",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(model.layers[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568e86c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
